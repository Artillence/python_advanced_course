{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c93aa83",
   "metadata": {},
   "source": [
    "# Day 3 - Parallel and High-Performance Python: Threads, AsyncIO, NumPy, Numba, GPUs\n",
    "\n",
    "Welcome to Day 3 of the advanced Python course. Today we focus on **performance** and **parallelism**.\n",
    "\n",
    "We will connect Python language features with how modern CPUs and GPUs execute code. The examples are oriented around physics and mechanical **size/length measurement** data (surface roughness, thickness, diameter measurements, repeated measurements, etc.).\n",
    "\n",
    "## What we will cover today\n",
    "\n",
    "- CPU vs I/O bound work and a high level mental model of performance\n",
    "- The Global Interpreter Lock (GIL) and why it matters\n",
    "- Threads, processes, and when to use which\n",
    "- AsyncIO for I/O-bound tasks (simulated sensor queries)\n",
    "- NumPy vectorized computations for numerical work\n",
    "- Numba JIT compilation for accelerating pure Python loops\n",
    "- A short overview of GPU tools: **cuDF**, **CuPy** and where they fit\n",
    "- A look at Python 3.13 and the future: experimental JIT and optional GIL\n",
    "- A complex end-to-end example: processing multiple measurement files in parallel\n",
    "\n",
    "## Daily agenda and course flow\n",
    "\n",
    "**09:00 - 10:30 (1h 30m)**  \n",
    "- CPU vs I/O bound tasks, performance model\n",
    "- GIL recap and impact on threading\n",
    "- Threads for I/O-bound workloads\n",
    "\n",
    "**10:30 - 10:45 (15m)**  \n",
    "- Short break\n",
    "\n",
    "**10:45 - 12:00 (1h 15m)**  \n",
    "- Processes for CPU-bound workloads\n",
    "- Intro to AsyncIO and simulated asynchronous measurements\n",
    "\n",
    "**12:00 - 13:00 (1h)**  \n",
    "- Lunch break\n",
    "\n",
    "**13:00 - 14:45 (1h 45m)**  \n",
    "- NumPy recap and vectorized computations for measurement data\n",
    "- Practical NumPy vectorization patterns and exercises (physics themed)\n",
    "\n",
    "**14:45 - 15:00 (15m)**  \n",
    "- Short break\n",
    "\n",
    "**15:00 - 16:30 (1h 30m)**  \n",
    "- Numba JIT compilation for numerical loops\n",
    "- Overview of GPU tools (cuDF, CuPy) and limitations\n",
    "- Python 3.13: experimental JIT and optional GIL, and what it may mean\n",
    "- Complex example: parallel processing of multiple measurement data sets\n",
    "\n",
    "Throughout the day, we will mark good points to pause, ask questions, or take a sip of water. Try to roughly follow the timing so that we finish comfortably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685d83a",
   "metadata": {},
   "source": [
    "## Topic 1 - Performance mental model: CPU vs I/O, GIL recap\n",
    "\n",
    "In real scientific and engineering work, **performance** usually means one of:\n",
    "\n",
    "- How fast we can process a large dataset (throughput)\n",
    "- How fast we get a single answer (latency)\n",
    "\n",
    "Python performance is strongly influenced by:\n",
    "\n",
    "- The speed of the underlying CPU or GPU\n",
    "- Whether our code is **CPU-bound** or **I/O-bound**\n",
    "- How much work we keep in **C-accelerated libraries** like NumPy\n",
    "- The **Global Interpreter Lock (GIL)** in CPython\n",
    "\n",
    "### CPU-bound vs I/O-bound\n",
    "\n",
    "- **CPU-bound**: most time is spent doing computations on the CPU.\n",
    "  - Example: computing statistics on millions of surface height samples.\n",
    "- **I/O-bound**: most time is spent waiting for input/output.\n",
    "  - Example: reading files from disk or waiting for a measurement device over the network.\n",
    "\n",
    "### GIL recap\n",
    "\n",
    "The CPython interpreter uses a **Global Interpreter Lock (GIL)**. Only one thread at a time can execute Python bytecode. This means:\n",
    "\n",
    "- Multiple threads do **not** speed up CPU-bound pure Python code.\n",
    "- Threads can still help with I/O-bound tasks, because while one thread waits for I/O, another can run.\n",
    "- Libraries that release the GIL internally (NumPy, some C extensions) can still run in parallel in C.\n",
    "\n",
    "For a deeper dive, see:\n",
    "\n",
    "- CPython GIL overview: https://wiki.python.org/moin/GlobalInterpreterLock\n",
    "- CPython implementation notes: https://docs.python.org/3/c-api/init.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ef409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU-bound function took ~0.083 s\n",
      "I/O-bound function took ~0.205 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def cpu_bound(n: int) -> int:\n",
    "    \"\"\"Fake CPU work: sum of squares up to n.\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i * i\n",
    "    return total\n",
    "\n",
    "def io_bound(delay: float) -> None:\n",
    "    \"\"\"Fake I/O: sleep to simulate waiting for a device or disk.\"\"\"\n",
    "    time.sleep(delay)\n",
    "\n",
    "start = time.perf_counter()\n",
    "cpu_bound(2_000_000)\n",
    "cpu_time = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "io_bound(0.2)\n",
    "io_time = time.perf_counter() - start\n",
    "\n",
    "print(f\"CPU-bound function took ~{cpu_time:.3f} s\")\n",
    "print(f\"I/O-bound function took ~{io_time:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef4152a",
   "metadata": {},
   "source": [
    "### üí™ Exercise (advanced): Rough timing experiment\n",
    "\n",
    "In this exercise you will run a tiny timing experiment to get a feel for the numbers.\n",
    "\n",
    "1. Use the provided `cpu_bound` function.\n",
    "2. Call it with different values, for example `50_000`, `200_000`, `500_000`, and measure the time for each.\n",
    "3. For timing, use `time.perf_counter()` like in the example.\n",
    "4. Print the `n` value and the time for each run.\n",
    "\n",
    "Do this in a simple, sequential loop. The goal is to get a feeling for how quickly Python loops slow down as `n` grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c94aeaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=500000, elapsed=0.0344 s\n",
      "n=2000000, elapsed=0.1341 s\n",
      "n=5000000, elapsed=0.3160 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Advanced exercise starter\n",
    "# TODO: run cpu_bound with several n values and measure the time.\n",
    "\n",
    "def cpu_bound(n: int) -> int:\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i * i\n",
    "    return total\n",
    "    \n",
    "ns = [50000, 200000, 500000]\n",
    "\n",
    "for n in ns:\n",
    "    # call cpu bound and measure time \n",
    "\n",
    "    print(f\"n={n}, elapsed={elapsed:.4f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de941549",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=50000, elapsed=0.0027 s\n",
      "n=200000, elapsed=0.0131 s\n",
      "n=500000, elapsed=0.0326 s\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import time\n",
    "\n",
    "def cpu_bound(n: int) -> int:\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i * i\n",
    "    return total\n",
    "\n",
    "ns = [50_000, 200_000, 500_000]\n",
    "for n in ns:\n",
    "    start = time.perf_counter()\n",
    "    _ = cpu_bound(n)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"n={n}, elapsed={elapsed:.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473ea2f",
   "metadata": {},
   "source": [
    "## Topic 2 - Threads for I/O-bound tasks\n",
    "\n",
    "Because of the GIL, Python threads are usually **not** a good solution for CPU-bound acceleration. But for I/O-bound tasks (waiting for files, network, measurement devices), threads can help hide latency.\n",
    "\n",
    "Typical pattern in lab / measurement setups:\n",
    "\n",
    "- You need to query multiple instruments or devices.\n",
    "- Each device responds in, say, 100 ms.\n",
    "- With sequential code, talking to 5 devices takes roughly 5 x 100 ms.\n",
    "- With threads, you can send requests in parallel and total time can be close to 100 ms.\n",
    "\n",
    "Python module: [`threading`](https://docs.python.org/3/library/threading.html)\n",
    "\n",
    "Note that this does not break the GIL for CPU work, but it is very useful to manage multiple slow I/O operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d575b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor 4: value=1.0816, delay=0.20s\n",
      "Sensor 2: value=0.9065, delay=0.30s\n",
      "Sensor 1: value=1.0224, delay=0.40s\n",
      "Sensor 3: value=1.0352, delay=0.60s\n",
      "Total elapsed (threaded): 0.627 s\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "from random import uniform\n",
    "\n",
    "def measure_sensor(sensor_id: int, delay: float) -> None:\n",
    "    \"\"\"Simulate a measurement: wait 'delay' seconds, then print a value.\"\"\"\n",
    "    time.sleep(delay)\n",
    "    value = uniform(0.9, 1.1)  # normalized size measurement\n",
    "    print(f\"Sensor {sensor_id}: value={value:.4f}, delay={delay:.2f}s\")\n",
    "\n",
    "delays = [0.4, 0.3, 0.6, 0.2]\n",
    "\n",
    "threads = []\n",
    "start = time.perf_counter()\n",
    "for i, d in enumerate(delays, start=1):\n",
    "    t = threading.Thread(target=measure_sensor, args=(i, d))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Total elapsed (threaded): {elapsed:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990f009a",
   "metadata": {},
   "source": [
    "### ‚úè Exercise (easy): Compare sequential vs threaded measurements\n",
    "\n",
    "Use the `measure_sensor` function idea to compare sequential and threaded execution.\n",
    "\n",
    "1. Re-implement a simple `measure_sensor` that sleeps and prints a message.\n",
    "2. First, call it sequentially in a loop for all delays.\n",
    "3. Then, call it using `threading.Thread` like in the example.\n",
    "4. Measure and print the elapsed time for both cases.\n",
    "\n",
    "You can reuse the list `delays = [0.4, 0.3, 0.6, 0.2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507a2633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential Run\n",
      "Sequential elapsed: 0.000 s\n",
      "\n",
      "Threaded Run\n",
      "Threaded elapsed: 0.000 s\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "from random import uniform\n",
    "\n",
    "# TODO: implement sequential and threaded measurement and compare their times.\n",
    "\n",
    "def measure_sensor(sensor_id: int, delay: float) -> None:\n",
    "    time.sleep(delay)\n",
    "    value = uniform(0.9, 1.1)\n",
    "    print(f\"Sensor {sensor_id}: value={value:.4f}, delay={delay:.2f}s\")\n",
    "\n",
    "delays = [0.4, 0.3, 0.6, 0.2]\n",
    "\n",
    "print(\"Sequential Run\")\n",
    "start = time.perf_counter()\n",
    "\n",
    "# TODO: Loop through 'delays' (use enumerate for sensor_id starting at 1).\n",
    "\n",
    "seq_elapsed = time.perf_counter() - start\n",
    "print(f\"Sequential elapsed: {seq_elapsed:.3f} s\")\n",
    "\n",
    "\n",
    "print(\"\\nThreaded Run\")\n",
    "threads = []\n",
    "start = time.perf_counter()\n",
    "\n",
    "# TODO: Loop through delays again.\n",
    "#       1. Create a Thread instance for each measure_sensor.\n",
    "#       2. Start the thread.\n",
    "#       3. Append the thread to the threads list.\n",
    "\n",
    "# TODO: Loop through the 'threads' list and call join() on each to wait for completion.\n",
    "\n",
    "thr_elapsed = time.perf_counter() - start\n",
    "print(f\"Threaded elapsed: {thr_elapsed:.3f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de51e38e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor 1: value=1.0886, delay=0.40s\n",
      "Sensor 2: value=0.9940, delay=0.30s\n",
      "Sensor 3: value=0.9065, delay=0.60s\n",
      "Sensor 4: value=1.0301, delay=0.20s\n",
      "Sequential elapsed: 1.505 s\n",
      "Sensor 4: value=1.0565, delay=0.20s\n",
      "Sensor 2: value=0.9084, delay=0.30s\n",
      "Sensor 1: value=0.9360, delay=0.40s\n",
      "Sensor 3: value=1.0763, delay=0.60s\n",
      "Threaded elapsed: 0.608 s\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import threading\n",
    "import time\n",
    "from random import uniform\n",
    "\n",
    "def measure_sensor(sensor_id: int, delay: float) -> None:\n",
    "    time.sleep(delay)\n",
    "    value = uniform(0.9, 1.1)\n",
    "    print(f\"Sensor {sensor_id}: value={value:.4f}, delay={delay:.2f}s\")\n",
    "\n",
    "delays = [0.4, 0.3, 0.6, 0.2]\n",
    "\n",
    "# Sequential\n",
    "start = time.perf_counter()\n",
    "for i, d in enumerate(delays, start=1):\n",
    "    measure_sensor(i, d)\n",
    "seq_elapsed = time.perf_counter() - start\n",
    "print(f\"Sequential elapsed: {seq_elapsed:.3f} s\")\n",
    "\n",
    "# Threaded\n",
    "threads = []\n",
    "start = time.perf_counter()\n",
    "for i, d in enumerate(delays, start=1):\n",
    "    t = threading.Thread(target=measure_sensor, args=(i, d))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "thr_elapsed = time.perf_counter() - start\n",
    "print(f\"Threaded elapsed: {thr_elapsed:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174bcf1",
   "metadata": {},
   "source": [
    "### üí™ Exercise (advanced): Collect results into a shared list\n",
    "\n",
    "Right now, `measure_sensor` just prints values. In real life, we want to **store** results.\n",
    "\n",
    "1. Modify `measure_sensor` so that it appends `(sensor_id, value)` to a shared list.\n",
    "2. Use a `threading.Lock` to protect the shared list.\n",
    "3. After all threads finish, print the collected list of results.\n",
    "\n",
    "This pattern mimics collecting measurement results from multiple devices into a shared in-memory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bb41945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 0.9803299653662977), (2, 0.9926811121605301), (1, 0.9047594144771355), (3, 0.9093203053674115)]\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "from random import uniform\n",
    "\n",
    "results = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "def measure_and_store(sensor_id: int, delay: float) -> None:\n",
    "    \"\"\"TODO: simulate measurement and safely append to results.\"\"\"\n",
    "    # time.sleep(delay)\n",
    "    # value = uniform(0.9, 1.1)\n",
    "\n",
    "    # TODO: store values\n",
    "    \n",
    "\n",
    "delays = [0.4, 0.3, 0.6, 0.2]\n",
    "threads = []\n",
    "# TODO: start threads using measure_and_store and join them, then print results.\n",
    "for i, d in enumerate(delays, start=1):\n",
    "    t = threading.Thread(target=measure_and_store, args=(i, d))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8e31b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected results: [(4, 1.0242552744792301), (2, 0.9700888704122314), (1, 1.0925002232553185), (3, 0.9773592353806989)]\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import threading\n",
    "import time\n",
    "from random import uniform\n",
    "\n",
    "results = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "def measure_and_store(sensor_id: int, delay: float) -> None:\n",
    "    time.sleep(delay)\n",
    "    value = uniform(0.9, 1.1)\n",
    "    with lock:\n",
    "        results.append((sensor_id, value))\n",
    "\n",
    "delays = [0.4, 0.3, 0.6, 0.2]\n",
    "threads = []\n",
    "for i, d in enumerate(delays, start=1):\n",
    "    t = threading.Thread(target=measure_and_store, args=(i, d))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Collected results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b13168",
   "metadata": {},
   "source": [
    "---\n",
    "# Short break (10:30 - 10:45)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f9eddc",
   "metadata": {},
   "source": [
    "## Topic 3 - Processes for CPU-bound workloads\n",
    "\n",
    "Because of the GIL, threads do not speed up CPU-bound pure Python loops. For heavy numerical work in pure Python, we can use **processes** instead of threads.\n",
    "\n",
    "Python module: [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html)\n",
    "\n",
    "A **process** has its own Python interpreter and its own GIL, so multiple processes can truly run in parallel on multiple CPU cores.\n",
    "\n",
    "Typical pattern in scientific computing:\n",
    "\n",
    "- Split a large dataset into chunks (e.g. surface height maps for different samples).\n",
    "- Spawn a pool of worker processes.\n",
    "- Each process computes statistics for one chunk.\n",
    "- Collect results in the main process.\n",
    "\n",
    "Downside: processes have more overhead than threads (especially for sending large arrays between processes), but they allow true CPU-core scaling for pure Python loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff7ca47",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 10 CPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-5:\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_rms' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_rms' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_rms' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'compute_rms' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-14:\n",
      "Process SpawnPoolWorker-12:\n",
      "Process SpawnPoolWorker-11:\n",
      "Process SpawnPoolWorker-10:\n",
      "Process SpawnPoolWorker-9:\n",
      "Process SpawnPoolWorker-8:\n",
      "Process SpawnPoolWorker-7:\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-13:\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
      "    with self._rlock:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 385, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrms\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m m\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     20\u001b[39m start = time.perf_counter()\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool() \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     rms_values = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_rms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m elapsed = time.perf_counter() - start\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal elapsed (threaded): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m s\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:367\u001b[39m, in \u001b[36mPool.map\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    363\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    in a list that is returned.\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:768\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ready():\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:765\u001b[39m, in \u001b[36mApplyResult.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:659\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    657\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# RUN FROM .py INSTEAD OF NOTEBOOK\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "def compute_rms(values):\n",
    "    \"\"\"Compute RMS roughness of a list of heights.\"\"\"\n",
    "    s = 0.0\n",
    "    for x in values:\n",
    "        s += x * x\n",
    "    return math.sqrt(s / len(values))\n",
    "\n",
    "def main():\n",
    "    # Create fake measurement data: 4 samples with 100_000 points each\n",
    "    samples = [[random.uniform(-1e-6, 1e-6) for _ in range(100_000)] for _ in range(4)]\n",
    "\n",
    "    print(f\"Using up to {cpu_count()} CPU cores\")\n",
    "    start = time.perf_counter()\n",
    "    with Pool() as pool:\n",
    "        rms_values = pool.map(compute_rms, samples)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"Total elapsed (threaded): {elapsed:.3f} s\")\n",
    "    \n",
    "    print(\"RMS roughness per sample:\")\n",
    "    for i, rms in enumerate(rms_values, start=1):\n",
    "        print(f\"  Sample {i}: {rms:.3e} m\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea85b4",
   "metadata": {},
   "source": [
    "### ‚úè Exercise (easy): Parallel average diameter per batch\n",
    "\n",
    "Imagine you have several batches of diameter measurements for different parts. Each batch is a list of floats.\n",
    "\n",
    "1. Implement a function `average(values)` that computes the mean of the list.\n",
    "2. Create a list of batches (for example 3-5 lists with random diameters in millimeters).\n",
    "3. Use `multiprocessing.Pool.map` to compute the average diameter for each batch in parallel.\n",
    "4. Print the result for each batch.\n",
    "\n",
    "Keep the batch sizes small enough that the code finishes quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN FROM .py INSTEAD OF NOTEBOOK\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "\n",
    "# TODO: compute average diameter per batch in parallel.\n",
    "\n",
    "def average(values):\n",
    "    # return ...\n",
    "\n",
    "# Create example batches of diameters in mm\n",
    "batches = [\n",
    "    [random.uniform(9.95, 10.05) for _ in range(50)],\n",
    "    [random.uniform(4.95, 5.05) for _ in range(80)],\n",
    "    [random.uniform(19.9, 20.1) for _ in range(100)],\n",
    "]\n",
    "\n",
    "def main():\n",
    "    # with Pool() as pool:\n",
    "    #     averages = ...\n",
    "    # for i, avg in enumerate(averages, start=1):\n",
    "    #     print(f\"Batch {i}: average diameter = {avg:.3f} mm\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f590d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Solution RUN FROM .py INSTEAD OF NOTEBOOK\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "\n",
    "def average(values):\n",
    "    total = 0.0\n",
    "    for v in values:\n",
    "        total += v\n",
    "    return total / len(values)\n",
    "\n",
    "batches = [\n",
    "    [random.uniform(9.95, 10.05) for _ in range(50)],\n",
    "    [random.uniform(4.95, 5.05) for _ in range(80)],\n",
    "    [random.uniform(19.9, 20.1) for _ in range(100)],\n",
    "]\n",
    "\n",
    "def main():\n",
    "    with Pool() as pool:\n",
    "        averages = pool.map(average, batches)\n",
    "    \n",
    "    for i, avg in enumerate(averages, start=1):\n",
    "        print(f\"Batch {i}: average diameter = {avg:.3f} mm\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9cab95",
   "metadata": {},
   "source": [
    "### üí™ Exercise (advanced): Parallel min, max, mean\n",
    "\n",
    "Extend the previous idea to compute **three** statistics per batch: `(min, max, mean)`.\n",
    "\n",
    "1. Write a function `stats(values)` that returns a tuple `(min_value, max_value, mean_value)`.\n",
    "2. Reuse or create batches of diameter or thickness measurements.\n",
    "3. Use a process pool to compute stats for each batch in parallel.\n",
    "4. Print the three statistics for each batch in a readable way.\n",
    "\n",
    "This is close to what you would actually do with per-sample measurement datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aee1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN FROM .py INSTEAD OF NOTEBOOK\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "\n",
    "def stats(values):\n",
    "    \"\"\"TODO: return (min, max, mean) for the list.\"\"\"\n",
    "    # m = min(values)\n",
    "    # M = max(values)\n",
    "    # mean = ...\n",
    "    # return m, M, mean\n",
    "    m = min(values)\n",
    "    M = max(values)\n",
    "    total = 0.0\n",
    "    for v in values:\n",
    "        total += v\n",
    "    mean = total / len(values)\n",
    "    return m, M, mean\n",
    "\n",
    "batches = [\n",
    "    [random.uniform(9.95, 10.05) for _ in range(50)],\n",
    "    [random.uniform(4.95, 5.05) for _ in range(80)],\n",
    "    [random.uniform(19.9, 20.1) for _ in range(100)],\n",
    "]\n",
    "\n",
    "def main():\n",
    "    # TODO: use Pool to compute stats in parallel and print them.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a11fe1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# RUN FROM .py INSTEAD OF NOTEBOOK\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "\n",
    "def stats(values):\n",
    "    m = min(values)\n",
    "    M = max(values)\n",
    "    total = 0.0\n",
    "    for v in values:\n",
    "        total += v\n",
    "    mean = total / len(values)\n",
    "    return m, M, mean\n",
    "\n",
    "batches = [\n",
    "    [random.uniform(9.95, 10.05) for _ in range(50)],\n",
    "    [random.uniform(4.95, 5.05) for _ in range(80)],\n",
    "    [random.uniform(19.9, 20.1) for _ in range(100)],\n",
    "]\n",
    "\n",
    "def main():\n",
    "    with Pool() as pool:\n",
    "        results = pool.map(stats, batches)\n",
    "    \n",
    "    for i, (m, M, mean) in enumerate(results, start=1):\n",
    "        print(f\"Batch {i}: min={m:.3f}, max={M:.3f}, mean={mean:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f7394-c8be-4c6b-ad8e-df7cda3ad40b",
   "metadata": {},
   "source": [
    "## Topic 4 - AsyncIO for concurrent I/O\n",
    "\n",
    "Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html) module lets you write **concurrent** programs using the `async` / `await` syntax.\n",
    "\n",
    "Unlike `threading` or `multiprocessing`, AsyncIO usually runs **in a single OS thread**. It uses an **event loop** that rapidly switches between many \"tasks\" (coroutines) whenever they are waiting for I/O.\n",
    "\n",
    "### Key concepts\n",
    "\n",
    "- **Coroutine**: a function defined with `async def`. Calling it does **not** run it, it returns a coroutine object (a bit like creating a `Task` in LabVIEW or a job in a scheduler).\n",
    "  ```python\n",
    "  async def measure():\n",
    "      ...\n",
    "  c = measure()  # coroutine object, not a result yet\n",
    "  ```\n",
    "- **Event loop**: a scheduler that runs coroutines. In scripts you usually start it with `asyncio.run(main())`. In Jupyter, the notebook already runs an event loop for you, so you can use `await` directly at the top level.\n",
    "- **`await`**: suspends the current coroutine until the awaited operation is finished, and lets the event loop run other tasks in the meantime.\n",
    "  - You can only use `await` **inside** `async def` functions (or at the top level in special environments like Jupyter).\n",
    "  - This is like saying \"I am waiting for the ADC / network / disk - while I wait, please do something else\".\n",
    "\n",
    "### When does AsyncIO help?\n",
    "\n",
    "AsyncIO is ideal when your program is **I/O bound** and spends most of its time waiting:\n",
    "\n",
    "- Many concurrent HTTP requests (web scraping, microservices).\n",
    "- Talking to many instruments over TCP/serial/USB at once.\n",
    "- File or database operations that frequently wait on the OS.\n",
    "\n",
    "It does **not** make pure Python CPU loops faster. The Global Interpreter Lock (GIL) still limits CPU bound code. For heavy numeric work you usually use:\n",
    "\n",
    "- **NumPy / vectorization** (day 3 topic),\n",
    "- **C / C++ extensions**, or\n",
    "- **multiprocessing** to use multiple cores.\n",
    "\n",
    "### How does control flow work?\n",
    "\n",
    "Think of the event loop as a conductor for an orchestra of coroutines:\n",
    "\n",
    "1. You define `async def` coroutines.\n",
    "2. You create tasks from them (for example with `asyncio.create_task`).\n",
    "3. The event loop picks a task, runs it until it hits an `await` on something that is not yet ready (e.g. `await asyncio.sleep(0.5)` or an async network call).\n",
    "4. At that `await`, the coroutine \"pauses\", the loop switches to another ready task.\n",
    "5. When the awaited I/O operation completes, the loop resumes the paused coroutine right after the `await`.\n",
    "\n",
    "Because tasks yield control at `await`, many of them can **make progress in overlapping time** - even though there is a single underlying OS thread.\n",
    "\n",
    "### Frequently asked questions\n",
    "\n",
    "**Q: Why can I not `await` in a normal function?**  \n",
    "Because the Python grammar only allows `await` inside `async def` (or in special interactive environments). A normal `def` function does not know how to suspend and resume itself. If you want to use `await`, you must either:\n",
    "- make the function `async def`, or\n",
    "- call an async function from the **outside** using `asyncio.run(my_async_main())` in a script.\n",
    "\n",
    "**Q: When is the event loop actually running?**  \n",
    "- In a **script**, when you call `asyncio.run(main())` (which internally creates and runs an event loop).\n",
    "- In **Jupyter**, there is already a loop running; the notebook integrates with it so `await` works at the top level. That is why you can simply do `await main()` in a notebook cell.\n",
    "\n",
    "**Q: How do I actually get real benefits?**  \n",
    "1. Identify I/O operations that can run in parallel (waiting for TCP sockets, serial ports, HTTP, `asyncio.sleep`, etc.).\n",
    "2. Wrap them in `async def` coroutines that `await` the I/O.\n",
    "3. Start many tasks with `asyncio.create_task` or `asyncio.gather`.\n",
    "4. Let the event loop interleave their waiting periods.\n",
    "\n",
    "Below we compare sequential vs async measurements to see the effect in practice.\n",
    "\n",
    "**Further reading:**\n",
    "- Official docs: https://docs.python.org/3/library/asyncio.html\n",
    "- \"Async IO in Python: A Complete Walkthrough\" (Real Python): https://realpython.com/async-io-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a94cecf1-af12-48ab-a24d-66ae4b8a36aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sequential sync measurements ---\n",
      "[sync ] Sensor 1: value=0.9644, delay=0.40s\n",
      "[sync ] Sensor 2: value=1.0050, delay=0.30s\n",
      "[sync ] Sensor 3: value=0.9401, delay=0.60s\n",
      "[sync ] Sensor 4: value=1.0310, delay=0.20s\n",
      "Sync total elapsed: 1.508 s\n",
      "\n",
      "--- Concurrent async measurements ---\n",
      "[async] Sensor 4: value=0.9038, delay=0.20s\n",
      "[async] Sensor 2: value=0.9559, delay=0.30s\n",
      "[async] Sensor 1: value=0.9855, delay=0.40s\n",
      "[async] Sensor 3: value=0.9426, delay=0.60s\n",
      "Async total elapsed: 0.602 s\n",
      "\n",
      "Sync values:  ['0.9644', '1.0050', '0.9401', '1.0310']\n",
      "Async values: ['0.9855', '0.9559', '0.9426', '0.9038']\n",
      "Max individual delay: 0.6 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from random import uniform\n",
    "\n",
    "# Synchronous version: measure each sensor one after the other\n",
    "\n",
    "def measure_sensor_sync(sensor_id: int, delay: float) -> float:\n",
    "    \"\"\"Simulate a blocking sensor measurement using time.sleep.\"\"\"\n",
    "    time.sleep(delay)\n",
    "    value = uniform(0.9, 1.1)\n",
    "    print(f\"[sync ] Sensor {sensor_id}: value={value:.4f}, delay={delay:.2f}s\")\n",
    "    return value\n",
    "\n",
    "# Async version: non-blocking wait with asyncio.sleep\n",
    "\n",
    "async def measure_sensor_async(sensor_id: int, delay: float) -> float:\n",
    "    \"\"\"Async measurement: uses await asyncio.sleep instead of time.sleep.\"\"\"\n",
    "    await asyncio.sleep(delay)\n",
    "    value = uniform(0.9, 1.1)\n",
    "    print(f\"[async] Sensor {sensor_id}: value={value:.4f}, delay={delay:.2f}s\")\n",
    "    return value\n",
    "\n",
    "async def main_compare_sync_vs_async() -> None:\n",
    "    delays = [0.4, 0.3, 0.6, 0.2]\n",
    "\n",
    "    print(\"\\n--- Sequential sync measurements ---\")\n",
    "    start_sync = time.perf_counter()\n",
    "    sync_values = [measure_sensor_sync(i, d) for i, d in enumerate(delays, start=1)]\n",
    "    elapsed_sync = time.perf_counter() - start_sync\n",
    "    print(f\"Sync total elapsed: {elapsed_sync:.3f} s\")\n",
    "\n",
    "    print(\"\\n--- Concurrent async measurements ---\")\n",
    "    start_async = time.perf_counter()\n",
    "    # Create tasks for all sensors\n",
    "    tasks = [asyncio.create_task(measure_sensor_async(i, d))\n",
    "             for i, d in enumerate(delays, start=1)]\n",
    "    # Wait for all tasks to finish\n",
    "    async_values = await asyncio.gather(*tasks)\n",
    "    elapsed_async = time.perf_counter() - start_async\n",
    "    print(f\"Async total elapsed: {elapsed_async:.3f} s\")\n",
    "\n",
    "    print(\"\\nSync values: \", [f\"{v:.4f}\" for v in sync_values])\n",
    "    print(\"Async values:\", [f\"{v:.4f}\" for v in async_values])\n",
    "    print(\"Max individual delay:\", max(delays), \"s\")\n",
    "\n",
    "# In a Jupyter notebook you can run the async main with top-level await:\n",
    "await main_compare_sync_vs_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea73886e-078b-4eb2-934e-cf3beb090417",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start async sleep\n",
      "Start normal sleep\n",
      "Normal sleep took 10.0050s\n",
      "Async sleep took 10.0058s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from random import uniform\n",
    "\n",
    "async def calculate_sync():\n",
    "    print(\"Start normal sleep\")\n",
    "    start = time.perf_counter()\n",
    "    time.sleep(10) # :(\n",
    "    print(f\"Normal sleep took {(time.perf_counter()-start):.4f}s\")\n",
    "\n",
    "async def sleep_async():\n",
    "    print(\"Start async sleep\")\n",
    "    start = time.perf_counter()\n",
    "    await asyncio.sleep(1)\n",
    "    print(f\"Async sleep took {(time.perf_counter()-start):.4f}s\")\n",
    "\n",
    "async def main_compare_sync_vs_async() -> None:\n",
    "    tasks = [\n",
    "        asyncio.create_task(sleep_async()),\n",
    "        asyncio.create_task(calculate_sync())\n",
    "    ]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# In a Jupyter notebook you can run the async main with top-level await:\n",
    "await main_compare_sync_vs_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f6fd8-9fcf-40e0-9ed2-8eb9fd3d5672",
   "metadata": {},
   "source": [
    "### ‚úè Exercise (easy): Measure async speedup factor\n",
    "\n",
    "Using the example above as a starting point:\n",
    "\n",
    "1. Copy the idea of `measure_sensor_async` and `asyncio.gather` into a new async function, for example `async_measure_many_sensors()`.\n",
    "2. Use a list of delays like `[0.1, 0.5, 0.2, 0.8, 0.3]`.\n",
    "3. Measure\n",
    "   - how long it would take to run all measurements **sequentially** (with `time.sleep`), and\n",
    "   - how long it takes to run them **concurrently** with AsyncIO.\n",
    "4. Print the **speedup factor** as `sync_time / async_time`.\n",
    "\n",
    "You already saw everything you need:\n",
    "- `time.perf_counter()` for timing,\n",
    "- `asyncio.create_task` + `asyncio.gather` for running tasks concurrently,\n",
    "- `await` inside `async def`.\n",
    "\n",
    "Think about why the async time is close to the **maximum** delay instead of the **sum** of delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b06b68ca-29d9-4d6f-b6a8-d677e1385451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sync ] Sensor 0: value=0.9168, delay=0.10s\n",
      "[sync ] Sensor 1: value=0.9389, delay=0.50s\n",
      "[sync ] Sensor 2: value=1.0828, delay=0.20s\n",
      "[sync ] Sensor 3: value=1.0502, delay=0.80s\n",
      "[sync ] Sensor 4: value=0.9927, delay=0.30s\n",
      "Sync time: 1.9079s\n",
      "[async] Sensor 1: value=1.0963, delay=0.10s\n",
      "[async] Sensor 3: value=1.0537, delay=0.20s\n",
      "[async] Sensor 5: value=1.0066, delay=0.30s\n",
      "[async] Sensor 2: value=0.9508, delay=0.50s\n",
      "[async] Sensor 4: value=1.0150, delay=0.80s\n",
      "Async time: 0.8012s\n",
      "Speedup factor: 2.3812\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from random import uniform\n",
    "\n",
    "# You can reuse or adapt these building blocks\n",
    "def measure_sensor_sync(sensor_id: int, delay: float) -> float:\n",
    "    time.sleep(delay)\n",
    "    value = uniform(0.9, 1.1)\n",
    "    print(f\"[sync ] Sensor {sensor_id}: value={value:.4f}, delay={delay:.2f}s\")\n",
    "    return value\n",
    "\n",
    "async def measure_sensor_async(sensor_id: int, delay: float) -> float:\n",
    "    await asyncio.sleep(delay)\n",
    "    value = uniform(0.9, 1.1)\n",
    "    print(f\"[async] Sensor {sensor_id}: value={value:.4f}, delay={delay:.2f}s\")\n",
    "    return value\n",
    "\n",
    "async def async_measure_many_sensors() -> None:\n",
    "    delays = [0.1, 0.5, 0.2, 0.8, 0.3]\n",
    "\n",
    "    # TODO:\n",
    "    # start = ...\n",
    "    for i, d in enumerate(delays):\n",
    "        measure_sensor_sync(i, d)\n",
    "    # t1 = ...\n",
    "    \n",
    "    print(f\"Sync time: {t1:.4f}s\")\n",
    "    \n",
    "    # 2) Measure async time by creating tasks and awaiting asyncio.gather.\n",
    "    # start = ...\n",
    "    # tasks = [asyncio.create_task(...)\n",
    "    #          for i, d in enumerate(delays, start=1)]\n",
    "    # await asyncio.gather(*tasks)\n",
    "    # t2 = ...\n",
    "    \n",
    "    # Print both times and the speedup factor (sync_time / async_time).\n",
    "    print(f\"Async time: {t2:.4f}s\")\n",
    "    print(f\"Speedup factor: {t1 / t2:.4f}\")\n",
    "\n",
    "# TODO: run async_measure_many_sensors from this cell using await.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e704fc5c-aa0c-4d7f-aa70-bf16931b1a11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sync elapsed:  1.904 s\n",
      "Async elapsed: 0.807 s\n",
      "Speedup:       2.36x\n",
      "Sync values:  ['1.0394', '1.0554', '0.9323', '0.9256', '0.9803']\n",
      "Async values: ['0.9262', '1.0007', '1.0895', '0.9597', '0.9325']\n"
     ]
    }
   ],
   "source": [
    "# Example solution for the easy async speedup exercise\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "from random import uniform\n",
    "\n",
    "\n",
    "def measure_sensor_sync(sensor_id: int, delay: float) -> float:\n",
    "    time.sleep(delay)\n",
    "    value = uniform(0.9, 1.1)\n",
    "    return value\n",
    "\n",
    "async def measure_sensor_async(sensor_id: int, delay: float) -> float:\n",
    "    await asyncio.sleep(delay)\n",
    "    value = uniform(0.9, 1.1)\n",
    "    return value\n",
    "\n",
    "async def async_measure_many_sensors() -> None:\n",
    "    delays = [0.1, 0.5, 0.2, 0.8, 0.3]\n",
    "\n",
    "    # Sequential measurements\n",
    "    start_sync = time.perf_counter()\n",
    "    sync_values = [measure_sensor_sync(i, d) for i, d in enumerate(delays, start=1)]\n",
    "    elapsed_sync = time.perf_counter() - start_sync\n",
    "\n",
    "    # Async concurrent measurements\n",
    "    start_async = time.perf_counter()\n",
    "    tasks = [asyncio.create_task(measure_sensor_async(i, d))\n",
    "             for i, d in enumerate(delays, start=1)]\n",
    "    async_values = await asyncio.gather(*tasks)\n",
    "    elapsed_async = time.perf_counter() - start_async\n",
    "\n",
    "    speedup = elapsed_sync / elapsed_async if elapsed_async > 0 else float(\"inf\")\n",
    "\n",
    "    print(f\"Sync elapsed:  {elapsed_sync:.3f} s\")\n",
    "    print(f\"Async elapsed: {elapsed_async:.3f} s\")\n",
    "    print(f\"Speedup:       {speedup:.2f}x\")\n",
    "    print(\"Sync values: \", [f\"{v:.4f}\" for v in sync_values])\n",
    "    print(\"Async values:\", [f\"{v:.4f}\" for v in async_values])\n",
    "\n",
    "await async_measure_many_sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c619540",
   "metadata": {},
   "source": [
    "---\n",
    "# Lunch break (12:00 - 13:00)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e944fc6",
   "metadata": {},
   "source": [
    "## Topic 5 - NumPy recap and basic vectorization\n",
    "\n",
    "[NumPy](https://numpy.org/) is the standard array library for numerical computing in Python.\n",
    "\n",
    "Key ideas:\n",
    "\n",
    "- A `numpy.ndarray` is an efficient, typed, homogeneous n-dimensional array.\n",
    "- Many operations are implemented in optimized C code.\n",
    "- Operations like `a + b`, `a * b` on arrays are **vectorized**: they run in fast loops in C rather than Python.\n",
    "\n",
    "In measurement and physics workflows, NumPy is ideal for:\n",
    "\n",
    "- Handling long arrays of measured values (heights, diameters, thicknesses, voltages).\n",
    "- Computing statistics and transformations (offset correction, unit conversion, normalization).\n",
    "- Applying elementwise functions (e.g. calibration curves, non-linear corrections).\n",
    "\n",
    "Make sure you have NumPy installed. In this course environment it should already be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982a09d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw thickness (um): [100.2  99.8 100.5 100.1  99.9 100.3 100.   99.7 100.4 100.1]\n",
      "Shape: (10,) dtype: float64\n",
      "Thickness (mm): [0.1002 0.0998 0.1005 0.1001 0.0999 0.1003 0.1    0.0997 0.1004 0.1001]\n",
      "Mean (um): 100.1\n",
      "Std (um): 0.24494897427831783\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Thickness measurements in micrometers for 10 samples\n",
    "thickness_um = np.array([100.2, 99.8, 100.5, 100.1, 99.9, 100.3, 100.0, 99.7, 100.4, 100.1])\n",
    "print(\"Raw thickness (um):\", thickness_um)\n",
    "print(\"Shape:\", thickness_um.shape, \"dtype:\", thickness_um.dtype)\n",
    "\n",
    "# Convert to millimeters\n",
    "thickness_mm = thickness_um / 1000.0\n",
    "print(\"Thickness (mm):\", thickness_mm)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Mean (um):\", thickness_um.mean())\n",
    "print(\"Std (um):\", thickness_um.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9449ce64",
   "metadata": {},
   "source": [
    "### ‚úè Exercise (easy): Diameter conversion and simple statistics\n",
    "\n",
    "1. Create a NumPy array of diameters in millimeters for at least 8 parts.\n",
    "2. Convert them to micrometers (multiply by 1000).\n",
    "3. Compute and print the mean and standard deviation in micrometers.\n",
    "\n",
    "Use the same patterns as in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c155f9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diameters (um): [1000. 1000. 1000. ... 1000. 1000. 1000.]\n",
      "Mean (um): 1000.0\n",
      "Std (um): 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: diameter conversion and basic statistics with NumPy.\n",
    "\n",
    "# diam_mm = \n",
    "# diam_um = \n",
    "# mean_um = \n",
    "# std_um = \n",
    "print(\"Diameters (um):\", diam_um)\n",
    "print(\"Mean (um):\", mean_um)\n",
    "print(\"Std (um):\", std_um)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d64f6237",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diameters (um): [10010.  9990. 10020. 10000. 10030.  9980. 10010.  9970.]\n",
      "Mean (um): 10001.25\n",
      "Std (um): 18.99835519196333\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "diam_mm = np.array([10.01, 9.99, 10.02, 10.00, 10.03, 9.98, 10.01, 9.97])\n",
    "diam_um = diam_mm * 1000.0\n",
    "mean_um = diam_um.mean()\n",
    "std_um = diam_um.std()\n",
    "print(\"Diameters (um):\", diam_um)\n",
    "print(\"Mean (um):\", mean_um)\n",
    "print(\"Std (um):\", std_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd42de",
   "metadata": {},
   "source": [
    "### üí™ Exercise (advanced): Offset correction and normalized values\n",
    "\n",
    "Imagine your thickness sensor has a calibration offset error of +0.3 micrometers.\n",
    "\n",
    "1. Create an array of measured thicknesses in micrometers.\n",
    "2. Subtract the offset from all values to get corrected thicknesses.\n",
    "3. Compute the mean and standard deviation of the corrected values.\n",
    "4. Compute a normalized array where you subtract the mean and divide by the standard deviation.\n",
    "\n",
    "This pattern (offset correction + normalization) is common in data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe711695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: offset correction and normalization.\n",
    "# thickness_um = np.array([100.2, 100.0, 99.9, 100.4, 100.1, 99.8])\n",
    "# offset = 0.3\n",
    "# corrected = ...  # subtract offset\n",
    "# mean_corr = ...\n",
    "# std_corr = ...\n",
    "# normalized = ...  # (corrected - mean_corr) / std_corr\n",
    "# print(\"Corrected thickness (um):\", corrected)\n",
    "# print(\"Normalized values:\", normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b6355e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected thickness (um): [ 99.9  99.7  99.6 100.1  99.8  99.5]\n",
      "Normalized values: [ 0.6761234  -0.3380617  -0.84515425  1.69030851  0.16903085 -1.35224681]\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "thickness_um = np.array([100.2, 100.0, 99.9, 100.4, 100.1, 99.8])\n",
    "offset = 0.3\n",
    "corrected = thickness_um - offset\n",
    "mean_corr = corrected.mean()\n",
    "std_corr = corrected.std()\n",
    "normalized = (corrected - mean_corr) / std_corr\n",
    "print(\"Corrected thickness (um):\", corrected)\n",
    "print(\"Normalized values:\", normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e7649",
   "metadata": {},
   "source": [
    "## Topic 6 - NumPy vectorized computations in practice\n",
    "\n",
    "Now we go deeper into NumPy vectorization. We will use:\n",
    "\n",
    "- Elementwise operations on arrays\n",
    "- Boolean masks and filtering\n",
    "- Aggregations along axes (2D arrays)\n",
    "- Simple physics-themed computations\n",
    "\n",
    "NumPy allows you to write **array expressions** instead of Python `for` loops. These expressions are executed in optimized C loops under the hood.\n",
    "\n",
    "Useful links:\n",
    "\n",
    "- NumPy user guide: https://numpy.org/doc/stable/user/index.html\n",
    "- NumPy quickstart: https://numpy.org/doc/stable/user/quickstart.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759bf60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diameters: [10.01  9.97 10.05 10.02  9.94 10.    9.99]\n",
      "Deviation: [ 0.01 -0.03  0.05  0.02 -0.06  0.   -0.01]\n",
      "In spec mask: [ True  True False  True False  True  True]\n",
      "In spec diameters: [10.01  9.97 10.02 10.    9.99]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: filter diameters by tolerance\n",
    "diam_mm = np.array([10.01, 9.97, 10.05, 10.02, 9.94, 10.00, 9.99])\n",
    "target = 10.00\n",
    "tolerance = 0.03\n",
    "\n",
    "deviation = diam_mm - target\n",
    "mask_in_spec = np.abs(deviation) <= tolerance\n",
    "print(\"Diameters:\", diam_mm)\n",
    "print(\"Deviation:\", deviation)\n",
    "print(\"In spec mask:\", mask_in_spec)\n",
    "print(\"In spec diameters:\", diam_mm[mask_in_spec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28be655",
   "metadata": {},
   "source": [
    "### ‚úè Exercise (easy): Filter out-of-spec samples\n",
    "\n",
    "1. Create a NumPy array of length measurements in millimeters.\n",
    "2. Define a target and tolerance.\n",
    "3. Build a mask of samples that are **out of spec** (absolute deviation larger than tolerance).\n",
    "4. Print the array of out-of-spec values and their count.\n",
    "\n",
    "Use boolean masks like in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8814ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: filter out-of-spec length values using a boolean mask.\n",
    "\n",
    "# lengths_mm = np.array([49.98, 50.02, 49.95, 50.04, 50.01, 49.92])\n",
    "# target = ...\n",
    "# tolerance = ...\n",
    "# deviation = ...\n",
    "# mask_out = ...  # abs(deviation) > tolerance\n",
    "# print(\"Out-of-spec values:\", lengths_mm[mask_out])\n",
    "# print(\"Count:\", mask_out.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a1d642e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-spec values: [49.95 50.04 49.92]\n",
      "Count: 3\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "lengths_mm = np.array([49.98, 50.02, 49.95, 50.04, 50.01, 49.92])\n",
    "target = 50.00\n",
    "tolerance = 0.03\n",
    "deviation = lengths_mm - target\n",
    "mask_out = np.abs(deviation) > tolerance\n",
    "print(\"Out-of-spec values:\", lengths_mm[mask_out])\n",
    "print(\"Count:\", int(mask_out.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5ecefb",
   "metadata": {},
   "source": [
    "### üí™ Exercise (advanced): Repeated measurements per part (2D arrays)\n",
    "\n",
    "Suppose you measure the same part multiple times to estimate uncertainty.\n",
    "\n",
    "1. Create a 2D NumPy array `data` of shape `(n_parts, n_repeats)` containing diameters in mm.\n",
    "2. Compute the mean diameter **per part** (axis 1).\n",
    "3. Compute the standard deviation per part (axis 1).\n",
    "4. Compute the overall mean of all measurements.\n",
    "5. Print the per-part mean and standard deviation.\n",
    "\n",
    "You should use `data.mean(axis=1)` and `data.std(axis=1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: repeated measurement statistics with 2D arrays.\n",
    "\n",
    "# Example: 4 parts, 5 repeated measurements each\n",
    "# data = np.array([\n",
    "#     [10.01, 9.99, 10.00, 10.02, 9.98],\n",
    "#     [4.99, 5.01, 5.00, 5.02, 4.98],\n",
    "#     [19.98, 20.00, 20.01, 19.99, 20.02],\n",
    "#     [29.99, 30.01, 30.00, 30.02, 29.98],\n",
    "# ])\n",
    "\n",
    "# mean_per_part = ...  # data.mean(axis=1)\n",
    "# std_per_part = ...   # data.std(axis=1)\n",
    "# overall_mean = ...   # data.mean()\n",
    "\n",
    "# print(\"Mean per part:\", mean_per_part)\n",
    "# print(\"Std per part:\", std_per_part)\n",
    "# print(\"Overall mean:\", overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e901fac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per part: [10.  5. 20. 30.]\n",
      "Std per part: [0.01414214 0.01414214 0.01414214 0.01414214]\n",
      "Overall mean: 16.25\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([\n",
    "    [10.01, 9.99, 10.00, 10.02, 9.98],\n",
    "    [4.99, 5.01, 5.00, 5.02, 4.98],\n",
    "    [19.98, 20.00, 20.01, 19.99, 20.02],\n",
    "    [29.99, 30.01, 30.00, 30.02, 29.98],\n",
    "])\n",
    "\n",
    "mean_per_part = data.mean(axis=1)\n",
    "std_per_part = data.std(axis=1)\n",
    "overall_mean = data.mean()\n",
    "\n",
    "print(\"Mean per part:\", mean_per_part)\n",
    "print(\"Std per part:\", std_per_part)\n",
    "print(\"Overall mean:\", overall_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ffbbe4-720c-4ea2-a841-ca0d8ba9b9b6",
   "metadata": {},
   "source": [
    "### Vectorized physics-style computation example\n",
    "\n",
    "As a small example, imagine you measured heights `h` at given positions `x` along a line, and you want to approximate the area under the curve using the trapezoidal rule.\n",
    "\n",
    "The trapezoidal rule for arrays `x` and `h` can be written as:\n",
    "\n",
    "`area ‚âà sum( (h[i] + h[i+1]) / 2 * (x[i+1] - x[i]) )`\n",
    "\n",
    "We can implement this with pure NumPy, using slicing, without explicit Python loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5850bcb-7fa9-4f2f-baaf-aba34797db89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate area (um*mm): 100.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulate positions in mm and heights in micrometers\n",
    "x = np.linspace(0.0, 10.0, 1001)  # 0..10 mm, 1001 points\n",
    "h_um = 2.0 * np.sin(2 * np.pi * x / 10.0) + 10.0  # some periodic height pattern in um\n",
    "\n",
    "# Trapezoidal rule using vectorized slices\n",
    "dx = x[1:] - x[:-1]\n",
    "h_avg = (h_um[1:] + h_um[:-1]) / 2.0\n",
    "area_um_mm = np.sum(h_avg * dx)  # units: um * mm\n",
    "\n",
    "print(f\"Approximate area (um*mm): {area_um_mm:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c87a572",
   "metadata": {},
   "source": [
    "### üí™ Exercise (advanced - optional): Chain of vectorized operations\n",
    "\n",
    "Combine several vectorized operations into a small pipeline:\n",
    "\n",
    "1. Simulate an array of thicknesses in micrometers with `np.random.normal`.\n",
    "2. Apply an offset correction.\n",
    "3. Clip the values to a realistic range using `np.clip`.\n",
    "4. Convert to millimeters.\n",
    "5. Compute and print the mean and standard deviation in both units.\n",
    "\n",
    "Do not use explicit Python loops. Use NumPy array operations only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31633097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: implement the vectorized processing pipeline.\n",
    "\n",
    "# n = 1000\n",
    "# thickness_um = np.random.normal(loc=100.0, scale=0.5, size=n)\n",
    "# offset = 0.2\n",
    "# corrected = ...\n",
    "# clipped = ...  # np.clip\n",
    "# thickness_mm = ...\n",
    "# print statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f4c592d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (um): 99.80521127498606\n",
      "Std (um): 0.5115783054404365\n",
      "Mean (mm): 0.09980521127498607\n",
      "Std (mm): 0.0005115783054404363\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "n = 1000\n",
    "thickness_um = np.random.normal(loc=100.0, scale=0.5, size=n)\n",
    "offset = 0.2\n",
    "corrected = thickness_um - offset\n",
    "clipped = np.clip(corrected, 98.0, 102.0)\n",
    "thickness_mm = clipped / 1000.0\n",
    "\n",
    "print(\"Mean (um):\", clipped.mean())\n",
    "print(\"Std (um):\", clipped.std())\n",
    "print(\"Mean (mm):\", thickness_mm.mean())\n",
    "print(\"Std (mm):\", thickness_mm.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8572f",
   "metadata": {},
   "source": [
    "---\n",
    "# Short break (14:45 - 15:00)\n",
    "\n",
    "Final stretch: Numba, GPUs, Python 3.13, and a complex example.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe9c68c",
   "metadata": {},
   "source": [
    "## Topic 7 - Numba JIT compilation\n",
    "\n",
    "[Numba](https://numba.pydata.org/) is a Just-In-Time (JIT) compiler for Python functions that operate mainly on NumPy arrays and numbers.\n",
    "\n",
    "Basic usage:\n",
    "\n",
    "```python\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def f(x):\n",
    "    # numerical code\n",
    "    ...\n",
    "```\n",
    "\n",
    "When you first call `f`, Numba compiles it to machine code (using LLVM). Subsequent calls run at near-C speed.\n",
    "\n",
    "### Important: how Numba and NumPy interact\n",
    "\n",
    "- NumPy operations like `a + b` or `a.mean()` are already implemented in C.\n",
    "- However, **Python loops around those operations** still run in the Python interpreter.\n",
    "- Numba helps most when you have **custom loops and logic** that cannot be expressed as simple NumPy expressions.\n",
    "\n",
    "**Answering the question:** \"If Numba works with NumPy + Python code, and NumPy is already implemented in C, how does Numba JIT help?\"\n",
    "\n",
    "- NumPy is fast for each individual operation, but if you write Python like:\n",
    "  - `for i in range(n): result[i] = complex_expression(a[i], b[i])`\n",
    "  - this loop runs in Python and pays Python overhead per iteration.\n",
    "- Numba compiles the **whole loop** (and the operations inside it) into one optimized machine code function.\n",
    "- This removes Python overhead and can fuse several operations into one pass.\n",
    "\n",
    "In practice, combine them:\n",
    "\n",
    "- Use NumPy vectorization where it is natural.\n",
    "- Use Numba for custom numeric kernels that are hard to write as a single NumPy expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9a2cbc5-4863-49ef-968f-e34a917f953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.63.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (2.9 kB)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.46.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting numpy<2.4,>=1.22 (from numba)\n",
      "  Using cached numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Downloading numba-0.63.1-cp313-cp313-macosx_12_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.46.0-cp313-cp313-macosx_12_0_arm64.whl (37.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m37.2/37.2 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Installing collected packages: numpy, llvmlite, numba\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.4.1\n",
      "\u001b[2K    Uninstalling numpy-2.4.1:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.4.1\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [numba]‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/3\u001b[0m [numba]\n",
      "\u001b[1A\u001b[2KSuccessfully installed llvmlite-0.46.0 numba-0.63.1 numpy-2.3.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f86e07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python RMS: 1.000134, time=0.0116 s\n",
      "Numba RMS first call: 1.000134, time=0.4065 s (includes compile)\n",
      "Numba RMS second call: 1.000134, time=0.0001 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    njit = None\n",
    "    print(\"Numba is not installed in this environment. The examples will fall back to pure Python.\")\n",
    "\n",
    "def rms_python(arr: np.ndarray) -> float:\n",
    "    s = 0.0\n",
    "    n = arr.size\n",
    "    for i in range(n):\n",
    "        x = float(arr[i])\n",
    "        s += x * x\n",
    "    return math.sqrt(s / n)\n",
    "\n",
    "if njit is not None:\n",
    "    @njit\n",
    "    def rms_numba(arr):\n",
    "        s = 0.0\n",
    "        n = arr.size\n",
    "        for i in range(n):\n",
    "            x = arr[i]\n",
    "            s += x * x\n",
    "        return math.sqrt(s / n)\n",
    "else:\n",
    "    rms_numba = None\n",
    "\n",
    "# Test on a large array\n",
    "arr = np.random.normal(loc=0.0, scale=1.0, size=1_000_00)\n",
    "\n",
    "# Python version\n",
    "start = time.perf_counter()\n",
    "r1 = rms_python(arr)\n",
    "t_python = time.perf_counter() - start\n",
    "print(f\"Python RMS: {r1:.6f}, time={t_python:.4f} s\")\n",
    "\n",
    "if rms_numba is not None:\n",
    "    # First call includes compilation time\n",
    "    start = time.perf_counter()\n",
    "    r2 = rms_numba(arr)\n",
    "    t_first = time.perf_counter() - start\n",
    "    # Second call is fast\n",
    "    start = time.perf_counter()\n",
    "    r3 = rms_numba(arr)\n",
    "    t_numba = time.perf_counter() - start\n",
    "    print(f\"Numba RMS first call: {r2:.6f}, time={t_first:.4f} s (includes compile)\")\n",
    "    print(f\"Numba RMS second call: {r3:.6f}, time={t_numba:.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3c3f3",
   "metadata": {},
   "source": [
    "### ‚úè Exercise (easy): Numba-accelerated difference of squares\n",
    "\n",
    "1. Implement a function `diff_squares_python(a, b)` that for each element computes `a[i]**2 - b[i]**2`.\n",
    "2. Time it on large NumPy arrays.\n",
    "3. If Numba is available, implement `diff_squares_numba` with `@njit`.\n",
    "4. Compare the timings.\n",
    "\n",
    "Make sure you do not create new Python lists inside the function. Work directly with NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb29f7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (417586745.py, line 21)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfor i # ... (same logic as above)\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    njit = None\n",
    "    print(\"Numba not available - you can still implement the pure Python version.\")\n",
    "\n",
    "def diff_squares_python(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    n = a.size\n",
    "    out = np.empty_like(a)\n",
    "    # for i ...\n",
    "    return out\n",
    "\n",
    "if njit is not None:\n",
    "    @njit\n",
    "    def diff_squares_numba(a, b):\n",
    "        n = a.size\n",
    "        out = np.empty_like(a)\n",
    "        for i # ... (same logic as above)\n",
    "        return out\n",
    "\n",
    "# a = np.random.normal(size=200_000)\n",
    "# b = np.random.normal(size=200_000)\n",
    "# start = time.perf_counter()\n",
    "# out_py = diff_squares_python(a, b)\n",
    "# t_py = time.perf_counter() - start\n",
    "# print(f\"Python time: {t_py:.4f} s\")\n",
    "\n",
    "# if njit is not None:\n",
    "#     start = time.perf_counter()\n",
    "#     out_nb1 = diff_squares_numba(a, b)\n",
    "#     t_nb1 = time.perf_counter() - start\n",
    "#     start = time.perf_counter()\n",
    "#     out_nb2 = diff_squares_numba(a, b)\n",
    "#     t_nb2 = time.perf_counter() - start\n",
    "#     print(f\"Numba first call: {t_nb1:.4f} s, second call: {t_nb2:.4f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7881d0f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python time: 0.1173 s\n",
      "Numba first call: 0.5256 s, second call: 0.0005 s\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    njit = None\n",
    "    print(\"Numba not available - only Python version will run.\")\n",
    "\n",
    "def diff_squares_python(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    n = a.size\n",
    "    out = np.empty_like(a)\n",
    "    for i in range(n):\n",
    "        out[i] = a[i] * a[i] - b[i] * b[i]\n",
    "    return out\n",
    "\n",
    "if njit is not None:\n",
    "    @njit\n",
    "    def diff_squares_numba(a, b):\n",
    "        n = a.size\n",
    "        out = np.empty_like(a)\n",
    "        for i in range(n):\n",
    "            out[i] = a[i] * a[i] - b[i] * b[i]\n",
    "        return out\n",
    "\n",
    "a = np.random.normal(size=200_000)\n",
    "b = np.random.normal(size=200_000)\n",
    "\n",
    "start = time.perf_counter()\n",
    "out_py = diff_squares_python(a, b)\n",
    "t_py = time.perf_counter() - start\n",
    "print(f\"Python time: {t_py:.4f} s\")\n",
    "\n",
    "if njit is not None:\n",
    "    start = time.perf_counter()\n",
    "    out_nb1 = diff_squares_numba(a, b)\n",
    "    t_nb1 = time.perf_counter() - start\n",
    "    start = time.perf_counter()\n",
    "    out_nb2 = diff_squares_numba(a, b)\n",
    "    t_nb2 = time.perf_counter() - start\n",
    "    print(f\"Numba first call: {t_nb1:.4f} s, second call: {t_nb2:.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de043d52",
   "metadata": {},
   "source": [
    "### üí™ Exercise (advanced): Custom statistic with Numba\n",
    "\n",
    "Define a custom function that is harder to express with pure NumPy:\n",
    "\n",
    "1. Implement `moving_rms_python(arr, window)` that computes RMS roughness over a sliding window.\n",
    "   - For each position `i`, compute RMS of `arr[i : i+window]`.\n",
    "2. If Numba is available, implement `moving_rms_numba` using `@njit`.\n",
    "3. Compare performance on a large array.\n",
    "\n",
    "This is a common pattern when analyzing profiles from surface measurement devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    njit = None\n",
    "    print(\"Numba not available - you can still implement the Python version.\")\n",
    "\n",
    "def moving_rms_python(arr: np.ndarray, window: int) -> np.ndarray:\n",
    "    \"\"\"TODO: pure Python moving RMS.\"\"\"\n",
    "    n = arr.size\n",
    "    out = np.empty(n - window + 1, dtype=float)\n",
    "    for i in range(n - window + 1):\n",
    "        sum_squares = 0.0\n",
    "\n",
    "        # For each position i, compute RMS of arr[i : i+window].\n",
    "        for j in range(window):\n",
    "            # ...\n",
    "        out[i] = math.sqrt(sum_squares / window)\n",
    "    return out\n",
    "\n",
    "if njit is not None:\n",
    "    @njit\n",
    "    def moving_rms_numba(arr, window):\n",
    "        n = arr.size\n",
    "        out = np.empty(n - window + 1, dtype=float)\n",
    "        for i in range(n - window + 1):\n",
    "            sum_squares = 0.0\n",
    "    \n",
    "            # For each position i, compute RMS of arr[i : i+window].\n",
    "            for j in range(window):\n",
    "                # ... # Same logic as above\n",
    "            out[i] = math.sqrt(sum_squares / window)\n",
    "        return out\n",
    "\n",
    "# arr = np.random.normal(size=200_000)\n",
    "# window = 50\n",
    "# start = time.perf_counter()\n",
    "# r_py = moving_rms_python(arr, window)\n",
    "# t_py = time.perf_counter() - start\n",
    "# print(f\"Python moving RMS time: {t_py:.4f} s\")\n",
    "\n",
    "# if njit is not None:\n",
    "#     start = time.perf_counter()\n",
    "#     r_nb1 = moving_rms_numba(arr, window)\n",
    "#     t_nb1 = time.perf_counter() - start\n",
    "#     start = time.perf_counter()\n",
    "#     r_nb2 = moving_rms_numba(arr, window)\n",
    "#     t_nb2 = time.perf_counter() - start\n",
    "#     print(f\"Numba first call: {t_nb1:.4f} s, second call: {t_nb2:.4f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f197590",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python moving RMS time: 0.5878 s\n",
      "Numba first call: 0.0707 s, second call: 0.0017 s\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    njit = None\n",
    "    print(\"Numba not available - only Python version will run.\")\n",
    "\n",
    "def moving_rms_python(arr: np.ndarray, window: int) -> np.ndarray:\n",
    "    n = arr.size\n",
    "    out = np.empty(n - window + 1, dtype=float)\n",
    "    for i in range(n - window + 1):\n",
    "        s = 0.0\n",
    "        for j in range(window):\n",
    "            x = float(arr[i + j])\n",
    "            s += x * x\n",
    "        out[i] = math.sqrt(s / window)\n",
    "    return out\n",
    "\n",
    "if njit is not None:\n",
    "    @njit\n",
    "    def moving_rms_numba(arr, window):\n",
    "        n = arr.size\n",
    "        out = np.empty(n - window + 1, dtype=np.float64)\n",
    "        for i in range(n - window + 1):\n",
    "            s = 0.0\n",
    "            for j in range(window):\n",
    "                x = arr[i + j]\n",
    "                s += x * x\n",
    "            out[i] = math.sqrt(s / window)\n",
    "        return out\n",
    "\n",
    "arr = np.random.normal(size=200_000)\n",
    "window = 50\n",
    "\n",
    "start = time.perf_counter()\n",
    "r_py = moving_rms_python(arr, window)\n",
    "t_py = time.perf_counter() - start\n",
    "print(f\"Python moving RMS time: {t_py:.4f} s\")\n",
    "\n",
    "if njit is not None:\n",
    "    start = time.perf_counter()\n",
    "    r_nb1 = moving_rms_numba(arr, window)\n",
    "    t_nb1 = time.perf_counter() - start\n",
    "    start = time.perf_counter()\n",
    "    r_nb2 = moving_rms_numba(arr, window)\n",
    "    t_nb2 = time.perf_counter() - start\n",
    "    print(f\"Numba first call: {t_nb1:.4f} s, second call: {t_nb2:.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922bac8-432f-4a92-87ad-d2e7e87b15b4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Examples of when you cannot / should not use numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "191a0cf9-388c-41f7-af90-1d8edb7426c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of argument at /var/folders/fr/gyc8hsnd1834rb308w5cy65r0000gn/T/ipykernel_13631/3817865517.py (5)\n\nFile \"../../../../../../../var/folders/fr/gyc8hsnd1834rb308w5cy65r0000gn/T/ipykernel_13631/3817865517.py\", line 5:\n<source missing, REPL/exec in use?>\n\nDuring: Pass nopython_type_inference \n\nThis error may have been caused by the following argument(s):\n- argument 0: Cannot determine Numba type of <class 'dict'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypingError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m total\n\u001b[32m     13\u001b[39m data = {\u001b[33m\"\u001b[39m\u001b[33mshort\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mverylongkey\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcount_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:424\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args\u001b[39m\u001b[34m(self, *args, **kws)\u001b[39m\n\u001b[32m    420\u001b[39m         msg = (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e).rstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis error may have been caused \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    421\u001b[39m                \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m         e.patch_message(msg)\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtyping\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.UnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[32m    427\u001b[39m     error_rewrite(e, \u001b[33m'\u001b[39m\u001b[33munsupported_error\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:365\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[39m\u001b[34m(e, issue_type)\u001b[39m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mTypingError\u001b[39m: Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of argument at /var/folders/fr/gyc8hsnd1834rb308w5cy65r0000gn/T/ipykernel_13631/3817865517.py (5)\n\nFile \"../../../../../../../var/folders/fr/gyc8hsnd1834rb308w5cy65r0000gn/T/ipykernel_13631/3817865517.py\", line 5:\n<source missing, REPL/exec in use?>\n\nDuring: Pass nopython_type_inference \n\nThis error may have been caused by the following argument(s):\n- argument 0: Cannot determine Numba type of <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Code using arbitrary dictionaries \n",
    "\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def count_keys(d):\n",
    "    total = 0\n",
    "    for k in d:\n",
    "        if len(k) > 3:\n",
    "            total += 1\n",
    "    return total\n",
    "\n",
    "data = {\"short\": 1, \"verylongkey\": 2, \"x\": 3}\n",
    "print(count_keys(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9568c13-2b96-4383-8b47-f0f378a0fc0e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of argument at /var/folders/fr/gyc8hsnd1834rb308w5cy65r0000gn/T/ipykernel_13631/4283451336.py (6)\n\nFile \"../../../../../../../var/folders/fr/gyc8hsnd1834rb308w5cy65r0000gn/T/ipykernel_13631/4283451336.py\", line 6:\n<source missing, REPL/exec in use?>\n\nDuring: Pass nopython_type_inference \n\nThis error may have been caused by the following argument(s):\n- argument 0: Cannot determine Numba type of <class 'pandas.DataFrame'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypingError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     11\u001b[39m df = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[32m10_000\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[32m10_000\u001b[39m)})\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:424\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args\u001b[39m\u001b[34m(self, *args, **kws)\u001b[39m\n\u001b[32m    420\u001b[39m         msg = (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e).rstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis error may have been caused \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    421\u001b[39m                \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m         e.patch_message(msg)\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtyping\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.UnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[32m    427\u001b[39m     error_rewrite(e, \u001b[33m'\u001b[39m\u001b[33munsupported_error\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:365\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[39m\u001b[34m(e, issue_type)\u001b[39m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mTypingError\u001b[39m: Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of argument at /var/folders/fr/gyc8hsnd1834rb308w5cy65r0000gn/T/ipykernel_13631/4283451336.py (6)\n\nFile \"../../../../../../../var/folders/fr/gyc8hsnd1834rb308w5cy65r0000gn/T/ipykernel_13631/4283451336.py\", line 6:\n<source missing, REPL/exec in use?>\n\nDuring: Pass nopython_type_inference \n\nThis error may have been caused by the following argument(s):\n- argument 0: Cannot determine Numba type of <class 'pandas.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Pandas / high-level libraries\n",
    "\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def transform(df):\n",
    "    df[\"z\"] = df[\"x\"] + df[\"y\"]  # Pandas Series ops\n",
    "    return df\n",
    "\n",
    "df = pd.DataFrame({\"x\": range(10_000), \"y\": range(10_000)})\n",
    "transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554b94bc-2027-46ea-b479-5d116e8121d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "UnsupportedBytecodeError",
     "evalue": "The 'with (context manager) as (variable):' construct is not supported.. Raised from None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnsupportedBytecodeError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m fin:\n\u001b[32m      9\u001b[39m             fout.write(line.upper())\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mcopy_file\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest2.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:443\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args\u001b[39m\u001b[34m(self, *args, **kws)\u001b[39m\n\u001b[32m    441\u001b[39m             e.patch_message(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m.join((\u001b[38;5;28mstr\u001b[39m(e).rstrip(), help_msg)))\n\u001b[32m    442\u001b[39m     \u001b[38;5;66;03m# ignore the FULL_TRACEBACKS config, this needs reporting!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    445\u001b[39m     \u001b[38;5;28mself\u001b[39m._types_active_call.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:376\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args\u001b[39m\u001b[34m(self, *args, **kws)\u001b[39m\n\u001b[32m    374\u001b[39m return_val = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     return_val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margtypes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.ForceLiteralArg \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    378\u001b[39m     \u001b[38;5;66;03m# Received request for compiler re-entry with the list of arguments\u001b[39;00m\n\u001b[32m    379\u001b[39m     \u001b[38;5;66;03m# indicated by e.requested_args.\u001b[39;00m\n\u001b[32m    380\u001b[39m     \u001b[38;5;66;03m# First, check if any of these args are already Literal-ized\u001b[39;00m\n\u001b[32m    381\u001b[39m     already_lit_pos = [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m e.requested_args\n\u001b[32m    382\u001b[39m                        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[i], types.Literal)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:908\u001b[39m, in \u001b[36mDispatcher.compile\u001b[39m\u001b[34m(self, sig)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ev.trigger_event(\u001b[33m\"\u001b[39m\u001b[33mnumba:compile\u001b[39m\u001b[33m\"\u001b[39m, data=ev_details):\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m         cres = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m errors.ForceLiteralArg \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    910\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfolded\u001b[39m(args, kws):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:80\u001b[39m, in \u001b[36m_FunctionCompiler.compile\u001b[39m\u001b[34m(self, args, return_type)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, return_type):\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     status, retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status:\n\u001b[32m     82\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:94\u001b[39m, in \u001b[36m_FunctionCompiler._compile_cached\u001b[39m\u001b[34m(self, args, return_type)\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.TypingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28mself\u001b[39m._failed_cache[key] = e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/dispatcher.py:107\u001b[39m, in \u001b[36m_FunctionCompiler._compile_core\u001b[39m\u001b[34m(self, args, return_type)\u001b[39m\n\u001b[32m    104\u001b[39m flags = \u001b[38;5;28mself\u001b[39m._customize_flags(flags)\n\u001b[32m    106\u001b[39m impl = \u001b[38;5;28mself\u001b[39m._get_implementation(args, {})\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m cres = \u001b[43mcompiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_extra\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtargetdescr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtyping_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtargetdescr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtarget_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                              \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mpipeline_class\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Check typing error if object mode is used\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cres.typing_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m flags.enable_pyobject:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/compiler.py:739\u001b[39m, in \u001b[36mcompile_extra\u001b[39m\u001b[34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[39m\n\u001b[32m    715\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compiler entry point\u001b[39;00m\n\u001b[32m    716\u001b[39m \n\u001b[32m    717\u001b[39m \u001b[33;03mParameter\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    735\u001b[39m \u001b[33;03m    compiler pipeline\u001b[39;00m\n\u001b[32m    736\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    737\u001b[39m pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[32m    738\u001b[39m                           args, return_type, flags, \u001b[38;5;28mlocals\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_extra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/compiler.py:439\u001b[39m, in \u001b[36mCompilerBase.compile_extra\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;28mself\u001b[39m.state.lifted = ()\n\u001b[32m    438\u001b[39m \u001b[38;5;28mself\u001b[39m.state.lifted_from = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile_bytecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/compiler.py:505\u001b[39m, in \u001b[36mCompilerBase._compile_bytecode\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[33;03mPopulate and run pipeline for bytecode input\u001b[39;00m\n\u001b[32m    503\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.func_ir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/compiler.py:481\u001b[39m, in \u001b[36mCompilerBase._compile_core\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, errors.NumbaError):\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    482\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.status.fail_reason = e\n\u001b[32m    483\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_final_pipeline:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/compiler.py:473\u001b[39m, in \u001b[36mCompilerBase._compile_core\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    471\u001b[39m res = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[43mpm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.cr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    475\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/compiler_machinery.py:363\u001b[39m, in \u001b[36mPassManager.run\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, errors.NumbaError):\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    364\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mFailed in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m mode pipeline (step: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m % \\\n\u001b[32m    365\u001b[39m         (\u001b[38;5;28mself\u001b[39m.pipeline_name, pass_desc)\n\u001b[32m    366\u001b[39m     patched_exception = \u001b[38;5;28mself\u001b[39m._patch_error(msg, e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/compiler_machinery.py:356\u001b[39m, in \u001b[36mPassManager.run\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    354\u001b[39m pass_inst = _pass_registry.get(pss).pass_inst\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pass_inst, CompilerPass):\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_runPass\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_inst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLegacy pass in use\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/compiler_lock.py:35\u001b[39m, in \u001b[36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_acquire_compile_lock\u001b[39m(*args, **kwargs):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/compiler_machinery.py:311\u001b[39m, in \u001b[36mPassManager._runPass\u001b[39m\u001b[34m(self, index, pss, internal_state)\u001b[39m\n\u001b[32m    309\u001b[39m     mutated |= check(pss.run_initialization, internal_state)\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SimpleTimer() \u001b[38;5;28;01mas\u001b[39;00m pass_time:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     mutated |= \u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SimpleTimer() \u001b[38;5;28;01mas\u001b[39;00m finalize_time:\n\u001b[32m    313\u001b[39m     mutated |= check(pss.run_finalizer, internal_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/compiler_machinery.py:272\u001b[39m, in \u001b[36mPassManager._runPass.<locals>.check\u001b[39m\u001b[34m(func, compiler_state)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck\u001b[39m(func, compiler_state):\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     mangled = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mangled \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    274\u001b[39m         msg = (\u001b[33m\"\u001b[39m\u001b[33mCompilerPass implementations should return True/False. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    275\u001b[39m                \u001b[33m\"\u001b[39m\u001b[33mCompilerPass with name \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m did not.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/untyped_passes.py:86\u001b[39m, in \u001b[36mTranslateByteCode.run_pass\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m     84\u001b[39m bc = state[\u001b[33m'\u001b[39m\u001b[33mbc\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     85\u001b[39m interp = interpreter.Interpreter(func_id)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m func_ir = \u001b[43minterp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m state[\u001b[33m\"\u001b[39m\u001b[33mfunc_ir\u001b[39m\u001b[33m\"\u001b[39m] = func_ir\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/interpreter.py:1376\u001b[39m, in \u001b[36mInterpreter.interpret\u001b[39m\u001b[34m(self, bytecode)\u001b[39m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28mself\u001b[39m.scopes.append(global_scope)\n\u001b[32m   1375\u001b[39m flow = Flow(bytecode)\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m \u001b[43mflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;28mself\u001b[39m.dfa = AdaptDFA(flow)\n\u001b[32m   1378\u001b[39m \u001b[38;5;28mself\u001b[39m.cfa = AdaptCFA(flow)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/byteflow.py:126\u001b[39m, in \u001b[36mFlow.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_implicit_new_block(state):\n\u001b[32m    125\u001b[39m     \u001b[38;5;66;03m# check if this is a with...as, abort if so\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_guard_with_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# else split\u001b[39;00m\n\u001b[32m    128\u001b[39m     state.split_new_block()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gb99/work/Szamalk/2026_jan-feb/.venv/lib/python3.13/site-packages/numba/core/byteflow.py:312\u001b[39m, in \u001b[36mFlow._guard_with_as\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m next_op != \u001b[33m\"\u001b[39m\u001b[33mPOP_TOP\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    310\u001b[39m     msg = (\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33mwith (context manager) as (variable):\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mconstruct is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedBytecodeError(msg)\n",
      "\u001b[31mUnsupportedBytecodeError\u001b[39m: The 'with (context manager) as (variable):' construct is not supported.. Raised from None"
     ]
    }
   ],
   "source": [
    "# I/O-bound or non-numeric code\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def copy_file(in_path, out_path):\n",
    "    with open(in_path, \"r\") as fin, open(out_path, \"w\") as fout:\n",
    "        for line in fin:\n",
    "            fout.write(line.upper())\n",
    "\n",
    "copy_file(\"test.txt\", \"test2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dcc513a-d2fd-422d-977b-c1f0cfb59fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python best: 0.0038002079963916913\n",
      "Numba best: 0.036472667001362424\n"
     ]
    }
   ],
   "source": [
    "# Numba accelerates tight numeric loops on simple typed arrays; for object-heavy code (like strings, dicts, Python lists), it can be neutral or flat-out worse than pure Python\n",
    "\n",
    "import time\n",
    "from numba import jit\n",
    "\n",
    "def slow_py(xs):\n",
    "    s = 0\n",
    "    for x in xs:\n",
    "        s += len(str(x))  # string conversion, non-numeric\n",
    "    return s\n",
    "\n",
    "@njit\n",
    "def slow_numba(xs):\n",
    "    s = 0\n",
    "    for x in xs:\n",
    "        s += len(str(x))\n",
    "    return s\n",
    "\n",
    "xs = list(range(100_000))\n",
    "\n",
    "# Warmup\n",
    "slow_py(xs)\n",
    "slow_numba(xs)  # triggers compilation\n",
    "\n",
    "def bench(fn, xs, n=5):\n",
    "    best = float(\"inf\")\n",
    "    for _ in range(n):\n",
    "        t0 = time.perf_counter()\n",
    "        fn(xs)\n",
    "        dt = time.perf_counter() - t0\n",
    "        best = min(best, dt)\n",
    "    return best\n",
    "\n",
    "print(\"Python best:\", bench(slow_py, xs))\n",
    "print(\"Numba best:\", bench(slow_numba, xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4640ef65-2689-47a6-9ceb-72c5bec6adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 0.1890889580026851 12500002500000\n",
      "Numba: 0.318271708994871 12500002500000\n"
     ]
    }
   ],
   "source": [
    "# Tiny function call overhead: Numba loses\n",
    "\n",
    "import time\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def f_numba(x):\n",
    "    return x + 1\n",
    "\n",
    "def f_py(x):\n",
    "    return x + 1\n",
    "\n",
    "def bench(fn, n=5_000_000):\n",
    "    t0 = time.perf_counter()\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += fn(i)\n",
    "    dt = time.perf_counter() - t0\n",
    "    return dt, s\n",
    "\n",
    "# Warm up Numba compile\n",
    "f_numba(0)\n",
    "\n",
    "t_py, s_py = bench(f_py)\n",
    "t_numba, s_numba = bench(f_numba)\n",
    "\n",
    "print(\"Python:\", t_py, s_py)\n",
    "print(\"Numba:\", t_numba, s_numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51ab2b",
   "metadata": {},
   "source": [
    "## Topic 8 - GPU acceleration overview: cuDF and CuPy\n",
    "\n",
    "For very large datasets and heavy numerical work, GPUs can be useful.\n",
    "\n",
    "Two popular libraries in the Python ecosystem:\n",
    "\n",
    "- [CuPy](https://cupy.dev/):\n",
    "  - NumPy-like interface for arrays stored on a CUDA GPU.\n",
    "  - Many functions mirror the NumPy API (`cupy.array`, `cupy.mean`, etc.).\n",
    "- [cuDF](https://docs.rapids.ai/api/cudf/stable/):\n",
    "  - Part of the RAPIDS ecosystem: https://rapids.ai/\n",
    "  - Pandas-like DataFrame library running on the GPU.\n",
    "\n",
    "In many cases, the workflow is:\n",
    "\n",
    "- Move large arrays or tables to the GPU once.\n",
    "- Perform many operations there.\n",
    "- Move reduced results (e.g. aggregates) back to the CPU.\n",
    "\n",
    "In this course environment, GPUs might not be available, so the examples below are illustrative only. Do not worry if they raise `ImportError` - that is expected on a CPU-only machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba512f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array size: 1,000,000\n",
      "[NumPy / CPU]  mean=-0.00046, std=1.00085, time=0.0252 s\n",
      "CuPy is not installed. This example is for illustration only.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "N = 1_000_000  # size of the array\n",
    "\n",
    "print(f\"Array size: {N:,}\")\n",
    "\n",
    "# ---------------- CPU: NumPy ----------------\n",
    "t0 = time.perf_counter()\n",
    "a_cpu = np.random.normal(size=N)\n",
    "mean_cpu = a_cpu.mean()\n",
    "std_cpu = a_cpu.std()\n",
    "t1 = time.perf_counter()\n",
    "cpu_time = t1 - t0\n",
    "\n",
    "print(f\"[NumPy / CPU]  mean={mean_cpu:.5f}, std={std_cpu:.5f}, time={cpu_time:.4f} s\")\n",
    "\n",
    "# ---------------- GPU: CuPy (if available) ----------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    print(\"CuPy version:\", cp.__version__)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    a_gpu = cp.random.normal(size=N)\n",
    "    mean_gpu = a_gpu.mean()\n",
    "    std_gpu = a_gpu.std()\n",
    "    t1 = time.perf_counter()\n",
    "    gpu_time = t1 - t0\n",
    "\n",
    "    print(f\"[CuPy / GPU]  mean={float(mean_gpu):.5f}, std={float(std_gpu):.5f}, time={gpu_time:.4f} s\")\n",
    "    print(f\"Speedup (CPU time / GPU time): {cpu_time / gpu_time:.2f}x\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"CuPy is not installed. This example is for illustration only.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf814b48",
   "metadata": {},
   "source": [
    "## Topic 9 - Python 3.13 and the future: experimental JIT and optional GIL\n",
    "\n",
    "Recent and upcoming CPython releases are adding major performance features:\n",
    "\n",
    "- **Python 3.13** (released in 2024) includes:\n",
    "  - An experimental **free-threaded build** (optional no-GIL mode). See PEP 703.\n",
    "  - An experimental **JIT compiler** (PEP 744) that can speed up some workloads.\n",
    "  - These features are **off by default** and require special builds / flags.\n",
    "- Future versions (3.14 and beyond) are expected to improve JIT performance and evolve the no-GIL story.\n",
    "\n",
    "What this means for you in the medium term:\n",
    "\n",
    "- Well-written numeric Python might become faster without you changing code.\n",
    "- True multi-threaded CPU-bound Python code may become possible without having to use `multiprocessing`.\n",
    "- Libraries like Numba, cuDF, CuPy, and others will likely evolve to take advantage of new capabilities.\n",
    "\n",
    "Official resources:\n",
    "\n",
    "- What's new in Python 3.13: https://docs.python.org/3/whatsnew/3.13.html\n",
    "- PEP 703 (optional GIL): https://peps.python.org/pep-0703/\n",
    "- PEP 744 (JIT): https://peps.python.org/pep-0744/\n",
    "\n",
    "For now, you should still learn threads, processes, AsyncIO, NumPy, and Numba - these skills remain valuable regardless of how the interpreter evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d7fb711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Python version: 3.13.7 (main, Sep  2 2025, 14:16:00) [MSC v.1944 64 bit (AMD64)]\n",
      "Executable: C:\\Users\\gregk\\Desktop\\winpython\\WPy64-31700\\python\\python.exe\n",
      "Note: in standard CPython 3.13+, JIT and no-GIL builds are optional and may need explicit enabling.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"Running Python version:\", sys.version)\n",
    "print(\"Executable:\", sys.executable)\n",
    "print(\"Note: in standard CPython 3.13+, JIT and no-GIL builds are optional and may need explicit enabling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e665425-0ae0-4b23-ac83-b05c2d569204",
   "metadata": {},
   "source": [
    "## Comparing parallel strategies and numeric backends\n",
    "\n",
    "Up to now we have seen several different ways to \"go faster\":\n",
    "\n",
    "- `threading` for overlapping I/O waits\n",
    "- `multiprocessing` for real parallel CPU work\n",
    "- `asyncio` for cooperative, single-threaded concurrency\n",
    "- `numpy` for vectorized C loops\n",
    "- `numba` for JIT-compiling Python loops\n",
    "- GPU libraries like `cupy` (if available)\n",
    "\n",
    "This knowledge bit puts them **side by side** in a single script and measures them on small, controlled benchmarks. The goal is not to find the \"fastest ever\" configuration, but to build a **mental model**:\n",
    "\n",
    "- When does the **GIL** block speedups?\n",
    "- When do threads help, and when are they useless?\n",
    "- When do processes help?\n",
    "- When do NumPy and Numba \"escape\" the GIL and scale across cores, even with threads?\n",
    "- What happens if you misuse `asyncio` and call `time.sleep` instead of `await asyncio.sleep`?\n",
    "- Where do GPUs fit in if `cupy` is available?\n",
    "\n",
    "### Architecture recap and what we measure\n",
    "\n",
    "**1. Threads vs GIL**\n",
    "\n",
    "- Python threads share a single interpreter and a single **Global Interpreter Lock (GIL)**.\n",
    "- For **CPU-bound pure Python loops**, only one thread can run Python bytecode at a time.\n",
    "  - Expect: threads do **not** speed up CPU-bound Python loops.\n",
    "- For **I/O-bound work** (`time.sleep`, network, disk), threads can overlap waiting.\n",
    "  - Expect: threads can reduce total wall-clock time for many I/O waits.\n",
    "\n",
    "**2. Processes and `multiprocessing.Pool`**\n",
    "\n",
    "- Each process has its **own interpreter and its own GIL**.\n",
    "- CPU-bound work can truly run in parallel on multiple cores.\n",
    "- Downside: data must be serialized and sent between processes (overhead).\n",
    "- Expect: good speedup for heavy CPU-bound loops, as long as data is not too huge or passed too often.\n",
    "\n",
    "**3. `asyncio` and cooperative concurrency**\n",
    "\n",
    "- `asyncio` runs a single OS thread with an **event loop**.\n",
    "- Coroutines `async def ...` yield control when they hit `await` on something that is not ready (e.g. `await asyncio.sleep(0.3)` or network I/O).\n",
    "- If you accidentally use `time.sleep` inside `async def`, you block the entire event loop.\n",
    "- Expect:\n",
    "  - `asyncio` + `await asyncio.sleep` -> total time close to the **max** delay.\n",
    "  - `asyncio` + `time.sleep` -> behaves like slow sequential code.\n",
    "\n",
    "**4. NumPy: vectorized C loops, GIL released**\n",
    "\n",
    "- Elementwise and reduction operations in NumPy are implemented in C.\n",
    "- During these C loops, NumPy usually **releases the GIL**, so other threads can run in parallel C code.\n",
    "- Expect:\n",
    "  - Pure Python loop vs NumPy: NumPy should win for large arrays.\n",
    "  - Running several independent NumPy operations in threads can scale across cores, because they are not fighting over the GIL most of the time.\n",
    "\n",
    "Docs: https://numpy.org/doc/stable/  \n",
    "\n",
    "**5. Numba: JIT for custom numeric kernels**\n",
    "\n",
    "- `numba.njit` compiles numeric Python functions (using only numbers and arrays) to machine code via LLVM.\n",
    "- In \"nopython\" mode, the compiled code **releases the GIL**.\n",
    "- You can call the JIT-compiled function from several Python threads and get real parallel speedups.\n",
    "- Expect:\n",
    "  - Numba vs pure Python: Numba should be much faster for large numeric loops.\n",
    "  - Numba in threads: multiple JIT functions can run in parallel on multiple cores.\n",
    "\n",
    "Docs: https://numba.pydata.org/  \n",
    "\n",
    "**6. CuPy: NumPy-like arrays on the GPU**\n",
    "\n",
    "- `cupy` mirrors a large part of the NumPy API but executes on a CUDA GPU.\n",
    "- Moving data to/from GPU has a cost, but for large arrays and heavy operations the GPU can be much faster.\n",
    "- In this script, CuPy is **optional**:\n",
    "  - If `cupy` is not installed or no GPU is present, the script simply prints a notice and skips those parts.\n",
    "  - If it is available, we compare Python vs NumPy vs CuPy.\n",
    "\n",
    "Docs: https://cupy.dev/  \n",
    "\n",
    "### Overview table: when to expect speedups\n",
    "\n",
    "| Scenario                                      | Tool / approach                     | GIL released?            | When to expect speedup                                               | Typical use case                                                                 |\n",
    "|-----------------------------------------------|-------------------------------------|--------------------------|------------------------------------------------------------------------|----------------------------------------------------------------------------------|\n",
    "| CPU-bound pure Python loop                    | `threading`                         | No                       | Almost never; threads fight over the GIL                              | Do **not** use threads to speed up pure Python CPU work                          |\n",
    "| I/O-bound waits (sleep, network, disk)        | `threading`                         | Not relevant for waiting | Yes, if many independent I/O waits                                    | Query many instruments, HTTP endpoints, or files in parallel                     |\n",
    "| CPU-bound pure Python loop                    | `multiprocessing.Pool`              | Each process has own GIL | Yes, if per-task work is heavy enough to amortize process overhead    | Heavy numeric loops on independent chunks of data                                |\n",
    "| I/O-bound tasks with async APIs               | `asyncio` + `await`                 | Single-threaded          | Yes, many small I/O tasks can overlap                                 | High-concurrency network clients, async DB calls, many small I/O operations      |\n",
    "| I/O-bound but using `time.sleep` in async     | `asyncio` + `time.sleep` (bug)      | Single-threaded          | No, behaves like slow sequential code                                 | Anti-pattern: what *not* to do                                                   |\n",
    "| Vectorized numeric operations on arrays       | `numpy` (single-thread)             | Yes (inside NumPy)       | Large arrays, heavy elementwise/reduction operations                  | Numeric computing, physics data processing                                      |\n",
    "| Independent NumPy operations in several tasks | `numpy` + `threading`               | Yes                      | Yes, if each NumPy call is heavy and independent                      | Multiple independent signals or measurement channels in parallel                 |\n",
    "| Custom numeric loops on arrays                | `numba.njit`                        | Yes                      | Yes, especially if loops are complex and large                        | Custom kernels that are hard to express as simple NumPy expressions              |\n",
    "| Numba in several threads                      | `numba.njit` + `threading`          | Yes                      | Yes, if each JIT kernel call is heavy enough and data is independent  | Parallel processing of many independent profiles or signals                      |\n",
    "| Very large arrays, heavy elementwise ops      | `cupy` on GPU                       | N/A for GIL              | Yes, if data transfer is amortized and GPU is available               | Large-scale numerical work, ML preprocessing, array-heavy simulations            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810638c-c051-4085-9c73-b1facb13f804",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# RUN FROM A .py FILE (NOT DIRECTLY IN JUPYTER) FOR RELIABLE MULTIPROCESSING\n",
    "#\n",
    "# Example:\n",
    "#   python compare_parallel_backends.py\n",
    "#\n",
    "# This script compares:\n",
    "# - threading vs sequential for CPU-bound and I/O-bound tasks\n",
    "# - multiprocessing.Pool for CPU-bound work\n",
    "# - asyncio: correct (await asyncio.sleep) vs incorrect (time.sleep)\n",
    "# - NumPy vs pure Python, and NumPy in threads (GIL released)\n",
    "# - Numba vs pure Python, and Numba in threads (GIL released)\n",
    "# - Optional CuPy vs NumPy vs pure Python (if CuPy is installed)\n",
    "\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import threading\n",
    "import asyncio\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    njit = None\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "except ImportError:\n",
    "    cp = None\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Utility helpers\n",
    "# -------------------------------\n",
    "\n",
    "def print_section(title: str) -> None:\n",
    "    print(\"\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    print(title)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "def print_result(label: str, seconds: float) -> None:\n",
    "    print(f\"{label:<45} {seconds:8.3f} s\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 1. CPU-bound and I/O-bound basic functions\n",
    "# -------------------------------\n",
    "\n",
    "def cpu_bound_python(n: int) -> float:\n",
    "    \"\"\"Simple CPU-bound loop: sum of squares.\"\"\"\n",
    "    s = 0.0\n",
    "    for i in range(n):\n",
    "        s += i * i\n",
    "    return math.sqrt(s)\n",
    "\n",
    "\n",
    "def io_bound_sleep(delay: float) -> None:\n",
    "    \"\"\"Simple I/O-bound stand-in: sleep to simulate waiting.\"\"\"\n",
    "    time.sleep(delay)\n",
    "\n",
    "\n",
    "# For multiprocessing we need top-level worker functions\n",
    "\n",
    "def cpu_worker(n: int) -> float:\n",
    "    \"\"\"Worker function for multiprocessing.\"\"\"\n",
    "    return cpu_bound_python(n)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Threading: CPU-bound vs I/O-bound\n",
    "# -------------------------------\n",
    "\n",
    "def benchmark_threading() -> None:\n",
    "    print_section(\"1) Threading: CPU-bound vs I/O-bound\")\n",
    "\n",
    "    num_tasks_cpu = min(4, max(2, cpu_count()))\n",
    "    num_tasks_io = num_tasks_cpu\n",
    "\n",
    "    n_per_task = 300_000  # Adjust if this is too slow/fast\n",
    "    delays = [0.4, 0.3, 0.6, 0.2][:num_tasks_io]\n",
    "\n",
    "    # CPU-bound: sequential\n",
    "    print(\"CPU-bound Python loop (sum of squares)\")\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(num_tasks_cpu):\n",
    "        cpu_bound_python(n_per_task)\n",
    "    t_seq = time.perf_counter() - start\n",
    "    print_result(\"Sequential (CPU-bound, pure Python)\", t_seq)\n",
    "\n",
    "    # CPU-bound: threaded\n",
    "    threads: List[threading.Thread] = []\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(num_tasks_cpu):\n",
    "        t = threading.Thread(target=cpu_bound_python, args=(n_per_task,))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    t_thr = time.perf_counter() - start\n",
    "    print_result(\"Threaded (CPU-bound, pure Python)\", t_thr)\n",
    "\n",
    "    if t_thr > 0:\n",
    "        print(f\"Speedup (threaded / sequential)          {t_seq / t_thr:8.3f} x\")\n",
    "    print(\"Expected: little or no speedup because of the GIL for CPU-bound Python.\\n\")\n",
    "\n",
    "    # I/O-bound: sequential\n",
    "    print(\"I/O-bound simulation (sleep)\")\n",
    "    start = time.perf_counter()\n",
    "    for d in delays:\n",
    "        io_bound_sleep(d)\n",
    "    t_io_seq = time.perf_counter() - start\n",
    "    print_result(\"Sequential (I/O-bound)\", t_io_seq)\n",
    "\n",
    "    # I/O-bound: threaded\n",
    "    threads = []\n",
    "    start = time.perf_counter()\n",
    "    for d in delays:\n",
    "        t = threading.Thread(target=io_bound_sleep, args=(d,))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    t_io_thr = time.perf_counter() - start\n",
    "    print_result(\"Threaded (I/O-bound)\", t_io_thr)\n",
    "    if t_io_thr > 0:\n",
    "        print(f\"Speedup (threaded / sequential)          {t_io_seq / t_io_thr:8.3f} x\")\n",
    "    print(\"Expected: near speedup by approx sum(delays) / max(delays).\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Multiprocessing for CPU-bound work\n",
    "# -------------------------------\n",
    "\n",
    "def benchmark_multiprocessing() -> None:\n",
    "    print_section(\"2) Multiprocessing.Pool for CPU-bound work\")\n",
    "\n",
    "    num_tasks = min(4, max(2, cpu_count()))\n",
    "    n_per_task = 5_000_000\n",
    "\n",
    "    print(f\"Using up to {num_tasks} processes out of {cpu_count()} CPU cores.\")\n",
    "\n",
    "    # Sequential\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(num_tasks):\n",
    "        cpu_worker(n_per_task)\n",
    "    t_seq = time.perf_counter() - start\n",
    "    print_result(\"Sequential (CPU-bound, pure Python)\", t_seq)\n",
    "\n",
    "    # Multiprocessing\n",
    "    start = time.perf_counter()\n",
    "    with Pool(processes=num_tasks) as pool:\n",
    "        pool.map(cpu_worker, [n_per_task] * num_tasks)\n",
    "    t_mp = time.perf_counter() - start\n",
    "    print_result(\"Multiprocessing Pool (CPU-bound)\", t_mp)\n",
    "\n",
    "    if t_mp > 0:\n",
    "        print(f\"Speedup (multiprocessing / sequential)   {t_seq / t_mp:8.3f} x\")\n",
    "    print(\"Expected: clear speedup if per-task work is large enough.\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 4. asyncio: correct vs incorrect sleeping\n",
    "# -------------------------------\n",
    "\n",
    "async def async_measure_blocking(delay: float) -> float:\n",
    "    \"\"\"Bad async: uses time.sleep, blocks event loop.\"\"\"\n",
    "    time.sleep(delay)  # This blocks the whole event loop\n",
    "    return delay\n",
    "\n",
    "\n",
    "async def async_measure_proper(delay: float) -> float:\n",
    "    \"\"\"Good async: uses asyncio.sleep, yields control.\"\"\"\n",
    "    await asyncio.sleep(delay)\n",
    "    return delay\n",
    "\n",
    "\n",
    "async def _async_benchmark_inner() -> None:\n",
    "    delays = [0.1, 0.5, 0.2, 0.8, 0.3]\n",
    "\n",
    "    print_section(\"3) asyncio: blocking vs non-blocking usage\")\n",
    "\n",
    "    # Bad case: async functions using time.sleep\n",
    "    start = time.perf_counter()\n",
    "    tasks = [asyncio.create_task(async_measure_blocking(d)) for d in delays]\n",
    "    await asyncio.gather(*tasks)\n",
    "    t_blocking = time.perf_counter() - start\n",
    "    print_result(\"asyncio + time.sleep (anti-pattern)\", t_blocking)\n",
    "\n",
    "    # Good case: async functions using asyncio.sleep\n",
    "    start = time.perf_counter()\n",
    "    tasks = [asyncio.create_task(async_measure_proper(d)) for d in delays]\n",
    "    await asyncio.gather(*tasks)\n",
    "    t_proper = time.perf_counter() - start\n",
    "    print_result(\"asyncio + await asyncio.sleep()\", t_proper)\n",
    "\n",
    "    if t_proper > 0:\n",
    "        print(f\"Speedup (proper / blocking)             {t_blocking / t_proper:8.3f} x\")\n",
    "    print(\"Expected: proper async time ~ max(delay), blocking async time ~ sum(delays).\")\n",
    "\n",
    "\n",
    "def benchmark_asyncio() -> None:\n",
    "    # Run the async benchmark in a fresh event loop\n",
    "    asyncio.run(_async_benchmark_inner())\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 5. NumPy vs pure Python, and NumPy in threads\n",
    "# -------------------------------\n",
    "\n",
    "def cpu_numpy(arr: np.ndarray) -> float:\n",
    "    # Simple computation that forces a pass over the data\n",
    "    return float(np.sqrt(np.sum(arr * arr)))\n",
    "\n",
    "\n",
    "def cpu_python_from_array(arr: np.ndarray) -> float:\n",
    "    s = 0.0\n",
    "    # iterate over a Python list copy to emphasize Python loop overhead\n",
    "    for x in arr.tolist():\n",
    "        s += x * x\n",
    "    return math.sqrt(s)\n",
    "\n",
    "\n",
    "def benchmark_numpy() -> None:\n",
    "    print_section(\"4) NumPy vs pure Python, and NumPy in threads\")\n",
    "\n",
    "    n = 10_000_000\n",
    "    num_tasks = min(4, max(2, cpu_count()))\n",
    "    print(f\"Using array size n = {n}, tasks = {num_tasks}\")\n",
    "\n",
    "    base_arr = np.random.normal(size=n)\n",
    "\n",
    "    # Pure Python\n",
    "    start = time.perf_counter()\n",
    "    cpu_python_from_array(base_arr)\n",
    "    t_py = time.perf_counter() - start\n",
    "    print_result(\"Pure Python loop (single task)\", t_py)\n",
    "\n",
    "    # NumPy single task\n",
    "    start = time.perf_counter()\n",
    "    cpu_numpy(base_arr)\n",
    "    t_np = time.perf_counter() - start\n",
    "    print_result(\"NumPy vectorized (single task)\", t_np)\n",
    "\n",
    "    # NumPy sequential multi-task\n",
    "    arrays = [np.random.normal(size=n) for _ in range(num_tasks)]\n",
    "    start = time.perf_counter()\n",
    "    for a in arrays:\n",
    "        cpu_numpy(a)\n",
    "    t_np_seq = time.perf_counter() - start\n",
    "    print_result(\"NumPy multi-task (sequential)\", t_np_seq)\n",
    "\n",
    "    # NumPy threaded multi-task\n",
    "    threads: List[threading.Thread] = []\n",
    "    start = time.perf_counter()\n",
    "    for a in arrays:\n",
    "        t = threading.Thread(target=cpu_numpy, args=(a,))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    t_np_thr = time.perf_counter() - start\n",
    "    print_result(\"NumPy multi-task (threaded)\", t_np_thr)\n",
    "\n",
    "    if t_np_thr > 0:\n",
    "        print(f\"Speedup (threaded / sequential)         {t_np_seq / t_np_thr:8.3f} x\")\n",
    "    print(\"Expected: NumPy should be much faster than pure Python,\")\n",
    "    print(\"and multiple independent NumPy calls can scale with threads because NumPy releases the GIL.\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Numba vs pure Python, and Numba in threads\n",
    "# -------------------------------\n",
    "\n",
    "if njit is not None:\n",
    "    def cpu_python(n) -> float:\n",
    "        s = 0.0\n",
    "        for i in range(n):\n",
    "            s += i * i\n",
    "        return math.sqrt(s)\n",
    "    \n",
    "    @njit(nogil=True)\n",
    "    def cpu_numba(n: int) -> float:\n",
    "        s = 0.0\n",
    "        for i in range(n):\n",
    "            s += i * i\n",
    "        return math.sqrt(s)\n",
    "else:\n",
    "    cpu_numba = None  # type: ignore\n",
    "\n",
    "\n",
    "def benchmark_numba() -> None:\n",
    "    print_section(\"5) Numba vs pure Python, and Numba in threads\")\n",
    "\n",
    "    if cpu_numba is None:\n",
    "        print(\"Numba is not installed. Skipping Numba benchmarks.\")\n",
    "        return\n",
    "\n",
    "    n = 10_000_000\n",
    "    num_tasks = min(4, max(2, cpu_count()))\n",
    "\n",
    "    # Pure Python\n",
    "    start = time.perf_counter()\n",
    "    cpu_python(n)\n",
    "    t_py = time.perf_counter() - start\n",
    "    print_result(\"Pure Python loop (single task)\", t_py)\n",
    "\n",
    "    # Numba single task: first call (includes JIT compile)\n",
    "    start = time.perf_counter()\n",
    "    cpu_numba(n)\n",
    "    t_nb_first = time.perf_counter() - start\n",
    "    print_result(\"Numba single task (first call - compile)\", t_nb_first)\n",
    "\n",
    "    # Numba single task: second call (fast)\n",
    "    start = time.perf_counter()\n",
    "    cpu_numba(n)\n",
    "    t_nb = time.perf_counter() - start\n",
    "    print_result(\"Numba single task (warm)\", t_nb)\n",
    "\n",
    "    arrays = [n for _ in range(num_tasks)]\n",
    "\n",
    "    # Numba sequential multi-task\n",
    "    start = time.perf_counter()\n",
    "    for a in arrays:\n",
    "        cpu_numba(a)\n",
    "    t_nb_seq = time.perf_counter() - start\n",
    "    print_result(\"Numba multi-task (sequential)\", t_nb_seq)\n",
    "\n",
    "    # Numba threaded multi-task\n",
    "    threads: List[threading.Thread] = []\n",
    "    start = time.perf_counter()\n",
    "    for a in arrays:\n",
    "        t = threading.Thread(target=cpu_numba, args=(a,))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    t_nb_thr = time.perf_counter() - start\n",
    "    print_result(\"Numba multi-task (threaded)\", t_nb_thr)\n",
    "\n",
    "    if t_nb > 0:\n",
    "        print(f\"Speedup (Numba / pure Python, single)   {t_py / t_nb:8.3f} x\")\n",
    "    if t_nb_thr > 0:\n",
    "        print(f\"Speedup (threaded / sequential, Numba)  {t_nb_seq / t_nb_thr:8.3f} x\")\n",
    "    print(\"Expected: Numba should drastically beat pure Python for large arrays,\")\n",
    "    print(\"and multiple Numba kernels can run in parallel threads because Numba releases the GIL.\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Optional CuPy vs NumPy: heavy pairwise distances\n",
    "# -------------------------------\n",
    "\n",
    "def benchmark_cupy() -> None:\n",
    "    print_section(\"6) CuPy vs NumPy vs pure Python (optional GPU)\")\n",
    "\n",
    "    if cp is None:\n",
    "        print(\"CuPy is not installed or no GPU is available. Skipping CuPy benchmark.\")\n",
    "        return\n",
    "\n",
    "    # Size and iterations chosen so that:\n",
    "    # - NumPy is clearly faster than pure Python\n",
    "    # - CuPy has enough math work to amortize GPU overhead and usually win\n",
    "    n = 20_000_000\n",
    "    iters = 10\n",
    "    print(f\"Array size for this benchmark: n = {n}, iterations = {iters}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Pure Python baseline (simple work)\n",
    "    # -------------------------------\n",
    "    arr_py = np.random.normal(size=n)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    cpu_python_from_array(arr_py)\n",
    "    t_py = time.perf_counter() - start\n",
    "    print_result(\"Pure Python loop (CPU)\", t_py)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Heavy NumPy compute\n",
    "    # -------------------------------\n",
    "    arr_np = np.random.normal(size=n).astype(np.float32)\n",
    "\n",
    "    def heavy_numpy(x: np.ndarray, iters: int) -> float:\n",
    "        # Repeat a non-trivial math kernel several times\n",
    "        for _ in range(iters):\n",
    "            x = np.sin(x) + np.cos(x) * 1.000001 + np.sqrt(x * x + 0.1234)\n",
    "        return float(x.mean())\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    mean_np = heavy_numpy(arr_np, iters)\n",
    "    t_np = time.perf_counter() - start\n",
    "    print_result(\"NumPy (CPU, heavy trig loop)\", t_np)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Heavy CuPy compute (GPU)\n",
    "    # -------------------------------\n",
    "    # Transfer once, then ONLY measure math-heavy GPU work.\n",
    "    arr_gpu = cp.asarray(arr_np)\n",
    "\n",
    "    def heavy_cupy(x: \"cp.ndarray\", iters: int) -> float:\n",
    "        for _ in range(iters):\n",
    "            x = cp.sin(x) + cp.cos(x) * 1.000001 + cp.sqrt(x * x + 0.1234)\n",
    "        return float(x.mean())  # brings back a single scalar\n",
    "\n",
    "    # Just to see the copy cost, not included in t_gpu:\n",
    "    start_copy = time.perf_counter()\n",
    "    _ = cp.asarray(arr_np)\n",
    "    t_copy = time.perf_counter() - start_copy\n",
    "    print_result(\"Host -> GPU copy (one large array)\", t_copy)\n",
    "\n",
    "    # Now time only the compute-heavy kernel\n",
    "    start = time.perf_counter()\n",
    "    mean_gpu = heavy_cupy(arr_gpu, iters)\n",
    "    t_gpu = time.perf_counter() - start\n",
    "    print_result(\"CuPy (GPU, heavy trig loop)\", t_gpu)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Speedups\n",
    "    # -------------------------------\n",
    "    if t_np > 0:\n",
    "        print(f\"Speedup (NumPy / Python) {t_py / t_np:8.3f} x\")\n",
    "    if t_gpu > 0:\n",
    "        print(f\"Speedup (CuPy compute / NumPy compute)    {t_np / t_gpu:8.3f} x\")\n",
    "\n",
    "    print(\"Note: Here the GPU does repeated trig and sqrt operations,\")\n",
    "    print(\"so the work is compute-heavy rather than copy-heavy.\")\n",
    "    print(\"On a decent GPU, CuPy should clearly beat NumPy on the heavy loop above.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Main entry point\n",
    "# -------------------------------\n",
    "\n",
    "def main() -> None:\n",
    "    print(\"Python executable:\", sys.executable)\n",
    "    print(\"Python version:   \", sys.version.split()[0])\n",
    "    print(\"Detected CPU cores:\", cpu_count())\n",
    "    print(\"Numba available:\", bool(njit))\n",
    "    print(\"CuPy available:\", cp is not None)\n",
    "    print()\n",
    "\n",
    "    benchmark_threading()\n",
    "    benchmark_multiprocessing()\n",
    "    benchmark_asyncio()\n",
    "    benchmark_numpy()\n",
    "    benchmark_numba()\n",
    "    benchmark_cupy()\n",
    "\n",
    "    print(\"\\nAll benchmarks finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5823c",
   "metadata": {},
   "source": [
    "## Topic 10 - Complex example: parallel processing of measurement datasets\n",
    "\n",
    "In this final example we combine multiple ideas from today:\n",
    "\n",
    "- NumPy arrays and vectorized computations\n",
    "- Numba JIT for a custom numeric kernel (optional)\n",
    "- `multiprocessing` to process multiple independent datasets in parallel\n",
    "\n",
    "### Scenario\n",
    "\n",
    "You have several measurement files from a surface profiler. Each file contains a 1D height profile (in micrometers). For each profile, you want to:\n",
    "\n",
    "1. Load the data (in this notebook we will just simulate it).\n",
    "2. Apply an offset correction (subtract mean).\n",
    "3. Compute RMS roughness and peak-to-valley height (max - min).\n",
    "4. Return a small summary dictionary.\n",
    "\n",
    "Then, for many profiles (e.g. 8 or 16), you want to process them in parallel using multiple CPU cores.\n",
    "\n",
    "We will build:\n",
    "\n",
    "- A pure NumPy summary function.\n",
    "- Optionally a Numba-accelerated variant.\n",
    "- A small wrapper that can be used with `multiprocessing.Pool.map`.\n",
    "\n",
    "Your task is to fill in the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN FROM .py INSTEAD OF NOTEBOOK\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    njit = None\n",
    "\n",
    "def simulate_profile(n_points: int = 50_000) -> np.ndarray:\n",
    "    \"\"\"Simulate a 1D surface profile in micrometers.\"\"\"\n",
    "    x = np.linspace(0.0, 10.0, n_points)\n",
    "    base = 5.0 * np.sin(2 * np.pi * x / 5.0)\n",
    "    noise = np.random.normal(loc=0.0, scale=0.5, size=n_points)\n",
    "    return base + noise\n",
    "\n",
    "def summarize_profile_numpy(profile: np.ndarray) -> dict:\n",
    "    \"\"\"TODO: center profile and compute RMS and peak-to-valley using NumPy only.\"\"\"\n",
    "    # mean = ...\n",
    "    # centered = ...\n",
    "    # rms = ...\n",
    "    # ptv = ...\n",
    "    # return {\"mean\": float(mean), \"rms\": float(rms), \"ptv\": float(ptv)}\n",
    "    mean = profile.mean()\n",
    "    centered = profile - mean\n",
    "    rms = math.sqrt((centered * centered).mean())\n",
    "    ptv = float(centered.max() - centered.min())\n",
    "    return {\"mean\": float(mean), \"rms\": float(rms), \"ptv\": ptv}\n",
    "\n",
    "if njit is not None:\n",
    "    @njit\n",
    "    def summarize_profile_numba_kernel(profile):\n",
    "        n = profile.size\n",
    "        # Compute mean\n",
    "        s = 0.0\n",
    "        for i in range(n):\n",
    "            s += profile[i]\n",
    "        mean = s / n\n",
    "        # Compute RMS and min, max of centered profile\n",
    "        s2 = 0.0\n",
    "        min_c = 1e30\n",
    "        max_c = -1e30\n",
    "        for i in range(n):\n",
    "            c = profile[i] - mean\n",
    "            s2 += c * c\n",
    "            if c < min_c:\n",
    "                min_c = c\n",
    "            if c > max_c:\n",
    "                max_c = c\n",
    "        rms = math.sqrt(s2 / n)\n",
    "        ptv = max_c - min_c\n",
    "        return mean, rms, ptv\n",
    "\n",
    "def summarize_profile_numba(profile: np.ndarray) -> dict:\n",
    "    if njit is None:\n",
    "        return summarize_profile_numpy(profile)\n",
    "    mean, rms, ptv = summarize_profile_numba_kernel(profile)\n",
    "    return {\"mean\": float(mean), \"rms\": float(rms), \"ptv\": float(ptv)}\n",
    "\n",
    "def process_one_profile(args):\n",
    "    \"\"\"Wrapper for Pool.map: args could be (index, use_numba).\"\"\"\n",
    "    index, use_numba = args\n",
    "    profile = simulate_profile()\n",
    "    if use_numba:\n",
    "        summary = summarize_profile_numba(profile)\n",
    "    else:\n",
    "        summary = summarize_profile_numpy(profile)\n",
    "    summary[\"index\"] = index\n",
    "    return summary\n",
    "\n",
    "def main():\n",
    "    # TODO:\n",
    "    # 1) Create a list of indices, e.g. range(8)\n",
    "    # 2) Use Pool to process them in parallel\n",
    "    # 3) Print the summaries sorted by index\n",
    "    \n",
    "    # indices = ...\n",
    "    # args_list = [(i, True) for i in indices]\n",
    "    # with Pool() as pool:\n",
    "    #     results = pool.map(process_one_profile, args_list)\n",
    "    # results_sorted = sorted(results, key=lambda d: d[\"index\"])\n",
    "    # for r in results_sorted:\n",
    "    #     print(r)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97374360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution RUN FROM .py INSTEAD OF NOTEBOOK\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    njit = None\n",
    "\n",
    "def simulate_profile(n_points: int = 50_000) -> np.ndarray:\n",
    "    x = np.linspace(0.0, 10.0, n_points)\n",
    "    base = 5.0 * np.sin(2 * np.pi * x / 5.0)\n",
    "    noise = np.random.normal(loc=0.0, scale=0.5, size=n_points)\n",
    "    return base + noise\n",
    "\n",
    "def summarize_profile_numpy(profile: np.ndarray) -> dict:\n",
    "    mean = profile.mean()\n",
    "    centered = profile - mean\n",
    "    rms = math.sqrt((centered * centered).mean())\n",
    "    ptv = float(centered.max() - centered.min())\n",
    "    return {\"mean\": float(mean), \"rms\": float(rms), \"ptv\": ptv}\n",
    "\n",
    "if njit is not None:\n",
    "    @njit\n",
    "    def summarize_profile_numba_kernel(profile):\n",
    "        n = profile.size\n",
    "        s = 0.0\n",
    "        for i in range(n):\n",
    "            s += profile[i]\n",
    "        mean = s / n\n",
    "        s2 = 0.0\n",
    "        min_c = 1e30\n",
    "        max_c = -1e30\n",
    "        for i in range(n):\n",
    "            c = profile[i] - mean\n",
    "            s2 += c * c\n",
    "            if c < min_c:\n",
    "                min_c = c\n",
    "            if c > max_c:\n",
    "                max_c = c\n",
    "        rms = math.sqrt(s2 / n)\n",
    "        ptv = max_c - min_c\n",
    "        return mean, rms, ptv\n",
    "\n",
    "def summarize_profile_numba(profile: np.ndarray) -> dict:\n",
    "    if njit is None:\n",
    "        return summarize_profile_numpy(profile)\n",
    "    mean, rms, ptv = summarize_profile_numba_kernel(profile)\n",
    "    return {\"mean\": float(mean), \"rms\": float(rms), \"ptv\": float(ptv)}\n",
    "\n",
    "def process_one_profile(args):\n",
    "    index, use_numba = args\n",
    "    profile = simulate_profile()\n",
    "    if use_numba:\n",
    "        summary = summarize_profile_numba(profile)\n",
    "    else:\n",
    "        summary = summarize_profile_numpy(profile)\n",
    "    summary[\"index\"] = index\n",
    "    return summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    indices = list(range(8))\n",
    "    args_list = [(i, True) for i in indices]\n",
    "    with Pool() as pool:\n",
    "        results = pool.map(process_one_profile, args_list)\n",
    "    results_sorted = sorted(results, key=lambda d: d[\"index\"])\n",
    "    for r in results_sorted:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e1a87",
   "metadata": {},
   "source": [
    "## Day 3 summary\n",
    "\n",
    "Today you:\n",
    "\n",
    "- Built a mental model of **CPU-bound** vs **I/O-bound** workloads.\n",
    "- Reviewed the impact of the **GIL** on threads and why processes are used for CPU-bound speedups.\n",
    "- Used **threads** for concurrent I/O-style tasks, collecting results safely with locks.\n",
    "- Used **multiprocessing** to process independent batches of measurement data in parallel.\n",
    "- Learned the basics of **AsyncIO** and coordinated multiple async measurement coroutines.\n",
    "- Revisited **NumPy**, created arrays, applied vectorized transformations, and computed statistics for physics/measurement data.\n",
    "- Practiced boolean masks, axis-wise aggregations, and small vectorized physics-style calculations.\n",
    "- Used **Numba** to JIT-compile custom numeric kernels and understood how it complements NumPy.\n",
    "- Saw an overview of **GPU tools** like [CuPy](https://cupy.dev/) and [cuDF](https://docs.rapids.ai/api/cudf/stable/) for GPU acceleration.\n",
    "- Discussed **Python 3.13** and its experimental JIT and optional no-GIL builds, and how future CPython versions may affect performance.\n",
    "- Combined multiple concepts in a complex example: parallel processing of simulated surface profiles with NumPy, Numba, and multiprocessing.\n",
    "\n",
    "These tools and concepts form a practical toolbox for high-performance numerical work in Python, especially in physics and engineering contexts. On the next days you can build on this knowledge for more advanced machine learning and deep learning workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fabb85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
